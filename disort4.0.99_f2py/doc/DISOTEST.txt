# $Rev: 94 $ $Date: 2017-12-20 23:18:26 -0500 (Wed, 20 Dec 2017) $
DISORT Test Driver Documentation

There are two groups of DISORT test problems.

One group aims to test ACCURACY, the other CONSISTENCY.

ACCURACY PROBLEMS
-----------------
The aim of the 'accuracy' problems is to compare the results with answers
obtained on a Digital Alpha Workstation computer running DISORT entirely in
double precision (14 significant digits). These problems are not chosen to be
comprehensive but rather to test extreme values of the input parameters.
Hence, in cases where published tables exist, only a few cases from the tables
are examined. NOTE: When it is clear that a result should be zero -- for
example, the up-flux from a zero-albedo surface should be zero -- the "correct"
answer is set to zero. In fact, DISORT will usually return a very small
non-zero number in such cases, whose value depends intimately on the computer
being used. In parentheses beneath each result is printed its ratio to the
"correct" answers (contained in DATA statements). This ratio is calculated by
a small routine RATIO which protects against under- and over-flow and attempts
to return reasonable results. If the ratio threatens to bump up against the
largest or smallest number representable on your computer, it will be set to
that number (roughly). This can make the ratios differ from one computer to
the next. However, most of the ratios should be unity to at least a few
significant digits. If you run in less than 14 digit precision, a few ratios
will differ from unity, and a few of those will just print as '*********'
because you will be comparing very small numbers which are sensitive to
precision, and when they differ by orders of magnitude their ratio will not
print in the supplied F format. Some problems were designed specifically to
show this precision dependence, so that the user has fair warning about running
in low precision. The worst degradation in accuracy from running in low
precision occurs for non-absorbing cases (single scattering albedo = 1),
because the eigenvalue problem becomes degenerate and very sensitive to
round-off errors in that case.

Test problems 1 to 5 involve single purely scattering layers with successively
more difficult phase functions. Subcases are for varying optical depths and
single scattering albedos. For problems 1 and 3, Van de Hulst defines
reflectivity = pi * U0(top) / incident flux transmissivity = pi * U0(bottom)
/ incident flux where U0 = azimuthally-averaged intensity. We picked incident
flux = pi so that our U0's are equal to Van de Hulst's reflectivities and
transmissivities. DISORT reflected and transmitted fluxes must be divided by
the incident flux (pi) to compare to the 'FLUX' column in Van de Hulst. (Get
DISORT transmitted flux by summing the direct and diffuse parts.)

Test problem 6 checks purely absorbing cases with an increasingly complex mix
of boundary and internal sources. Solutions can be compared with exact
analytic results.

Test problem 7 checks a general emitting/absorbing/scattering medium with one
computational layer and an increasingly complex bottom reflectivity condition.

Test problem 8 checks an absorbing/isotropic-scattering medium with two
computational layers and isotropic incidence at the top boundary. Solutions
can be compared to published results.

Test problem 9 checks a general emitting/absorbing/scattering medium with every
computational layer different. Cases A,B can be compared to published results.
It also checks the special case in PLKAVG where the two wavenumbers are close.

Test problem 14 checks a transparent atmosphere with various surface
Bi-directional reflectivities. 
 
Test problem 15 checks a multi-layer atmosphere (one Rayleigh layer 
+ one aerosol layer) with various surface Bi-directional reflectivities. 
 
Test problem 16 displays the result of reflected intensity for a spherical
shell atmosphere. 
 
Test problem 17 checks the result of new Delta-M+ on aerosol and liquid 
water cloud cases.

CONSISTENCY PROBLEMS
--------------------
The aim of the 'consistency' problems is to compare the results obtained on two
successive calls to DISORT, for identical problem structures but taking
differing paths through the program. The answers obtained on the first call are
saved and used to calculate ratios after the second call. Thus, ratios are not
printed after the first call (but answers are). Test problem 10 checks that
USRANG = FALSE and USRANG = TRUE give identical results for the same set of
angles. It also checks the special case branch for a 2x2 eigenvalue problem.
Test problem 11 checks that identical answers are obtained when user levels in
a single layer are replaced by computational levels. Test problem 12 checks
whether the shortcut for large absorption optical depth (setting intensities to
zero below a certain absorption optical depth) is sufficiently accurate. This
is a 'worst case' problem in which a bottom boundary of albedo unity is
reflecting just below the cutoff level. The user must decide if he minds
having large percent errors in intensities which are negligibly small compared
to the incident intensities. Test problem 13 checks the option of determining
albedo and transmissivity for many sun angles at once. It computes intensities
(radiances) as a function of polar angle for uniform incidence, which due to
reciprocity is equivalent to fluxes (irradiances) for collimated beam incidence
(with beam angle equal to the polar angle). ONLYFL must be set to FALSE in
this case. 

NOTE: The references cited in some of the test problems can be found in the
DISORT documentation file. In the Garcia and Siewert tables (cf. test problems
4 and 5) the sign of the zenith angle is reversed from the convention used in
DISORT.

** WARNING ** Every effort has been made to make the test problems independent
of each other, so that 'hangover' values from one problem do not
unintentionally become input to the next; however, it is impossible to test all
possible permutations to be sure this is really true, and we could easily have
overlooked an isolated hangover or two. Furthermore, for the cases WITHIN a
given problem, we make full use of hangover values; thus re-arranging these
cases is almost certain to lead to incorrect results. Therefore, in modifying
these test problems or devising their own, users should: (a) be very careful to
set all input variables to DISORT before calling it (b) be aware of those few
DISORT arguments that function as both input and output, and not assume these
retain their initial values across multiple DISORT calls. 

** NOTE on compiling disotest.f90 ** When compiling disotest.f90 with DISORT.f
do not include the file BDREF.f. disotest.f90 already has a function BDREF used
in the test cases.

=================================================================== 
# Here is an extract from a C-shell script to run the normal (mixed single,
double precision) version with the test cases supplied in disotest.f90: 
set OutputFile = myOutputFile.txt
date > $OutputFile
cat DISORT.f ErrPack.f LINPAK.f R1MACH.f D1MACH.f > code.f
# compile+link (--> a.out)
f90 $CompilerOps disotest.f90 code.f >>& $OutputFile 
# make a.out executable
chmod u+x ./a.out
# Execute, merging std output and std error
# "./" ensures local a.out is executed
./a.out >>& $OutputFile
===================================================================
