{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb6eda2",
   "metadata": {},
   "source": [
    "Solving the radiative transfer equation for a single atmospheric layer using the discrete ordinates method in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7650e02f",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "by Dion Ho Jia Xu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d438e85f",
   "metadata": {
    "format": "row"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "from inspect import signature\n",
    "\n",
    "from math import pi\n",
    "from numpy.polynomial import legendre\n",
    "\n",
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd6607",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [1. USER INPUT REQUIRED: List of parameters to set](#1.-USER-INPUT-REQUIRED:-List-of-parameters-to-set)\n",
    "\t* [1.1 Hyperparameter list (excludes phase function) (TODO)](#1.1-Hyperparameter-list-%28excludes-phase-function%29-%28TODO%29)\n",
    "\t* [1.2 Computational variable list](#1.2-Computational-variable-list)\n",
    "\t* [1.3 Legendre expansion of the phase function](#1.3-Legendre-expansion-of-the-phase-function)\n",
    "\t\t* [1.3.1 Phase functions](#1.3.1-Phase-functions)\n",
    "\t\t* [1.3.2 $\\delta-M$ scaled Legendre coefficients](#1.3.2-$\\delta-M$-scaled-Legendre-coefficients)\n",
    "* [2. PyDISORT algorithm](#2.-PyDISORT-algorithm)\n",
    "\t* [2.1 Subroutines](#2.1-Subroutines)\n",
    "\t* [2.2 Main algorithms (TODO)](#2.2-Main-algorithms-%28TODO%29)\n",
    "\t\t* [2.2.1 Call PyDISORT (TODO)](#2.2.1-Call-PyDISORT-%28TODO%29)\n",
    "* [3. Breakdown and verification of single layer solver](#3.-Breakdown-and-verification-of-single-layer-solver)\n",
    "\t* [3.1 Quadrature](#3.1-Quadrature)\n",
    "\t\t* [3.1.1 Verification of quadrature weights and points on test integral](#3.1.1-Verification-of-quadrature-weights-and-points-on-test-integral)\n",
    "\t\t* [3.1.2 Normalization verification of the phase function](#3.1.2-Normalization-verification-of-the-phase-function)\n",
    "\t* [3.2 Re-derivation of equations (6a) to (6d) in Stamnes et. al., 1988](#3.2-Re-derivation-of-equations-%286a%29-to-%286d%29-in-Stamnes-et.-al.,-1988)\n",
    "\t\t* [3.2.1 Verification of subroutines](#3.2.1-Verification-of-subroutines)\n",
    "\t* [3.3 $\\delta-M$ scaling in the Radiative Transfer Equation](#3.3-$\\delta-M$-scaling-in-the-Radiative-Transfer-Equation)\n",
    "\t* [3.4 Re-derivation of equations (7a) and (7b) in Stamnes et. al., 1988](#3.4-Re-derivation-of-equations-%287a%29-and-%287b%29-in-Stamnes-et.-al.,-1988)\n",
    "\t* [3.5 Solving the system for each Fourier mode](#3.5-Solving-the-system-for-each-Fourier-mode)\n",
    "\t* [3.6 Constructing the general solution for each Fourier mode](#3.6-Constructing-the-general-solution-for-each-Fourier-mode)\n",
    "\t\t* [3.6.1 The particular solution](#3.6.1-The-particular-solution)\n",
    "\t\t* [3.6.2 The homogeneous solution](#3.6.2-The-homogeneous-solution)\n",
    "\t\t* [3.6.3 Verification of the general solution for one Fourier mode](#3.6.3-Verification-of-the-general-solution-for-one-Fourier-mode)\n",
    "\t* [3.7 The full solution](#3.7-The-full-solution)\n",
    "\t\t* [3.7.1 Nakajima-Tanaka (NT) corrections (TODO)](#3.7.1-Nakajima-Tanaka-%28NT%29-corrections-%28TODO%29)\n",
    "\t\t* [3.7.2 Verification of full solution](#3.7.2-Verification-of-full-solution)\n",
    "\t\t* [3.7.3 Computation of flux](#3.7.3-Computation-of-flux)\n",
    "\t\t\t* [3.7.3.1 Verification of flux](#3.7.3.1-Verification-of-flux)\n",
    "\t\t\t* [3.7.3.2 Computation of reflectivity and transmittivity](#3.7.3.2-Computation-of-reflectivity-and-transmittivity)\n",
    "\t\t* [3.7.4 Timing PyDISORT](#3.7.4-Timing-PyDISORT)\n",
    "* [4. Solving for multiple atmospheric layers (TODO)](#4.-Solving-for-multiple-atmospheric-layers-%28TODO%29)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252f792",
   "metadata": {},
   "source": [
    "We wish to solve the radiative transfer equation\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mu \\frac{\\partial u(\\tau, \\mu, \\phi)}{\\partial \\tau} = u(\\tau, \\mu, \\phi) &-\\frac{\\omega_0}{4 \\pi} \\int_{-1}^{1} \\int_{0}^{2 \\pi} p\\left(\\mu, \\phi ; \\mu', \\phi'\\right) u\\left(\\tau, \\mu', \\phi'\\right) \\mathrm{d} \\phi' \\mathrm{d} \\mu' \\\\\n",
    "&-\\frac{\\omega_0 I_0}{4 \\pi} p\\left(\\mu, \\phi ;-\\mu_{0}, \\phi_{0}\\right) \\exp\\left(-\\mu_{0}^{-1} \\tau\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "with Dirichlet boundary conditions for the **diffuse** intensity, $u = u_\\text{diffuse}$. This will be done numerically using the Discrete Ordinates Method. The total intensity is given by\n",
    "\n",
    "$$u_\\text{total} = u_\\text{diffuse} + u_\\text{direct}$$\n",
    "\n",
    "where \n",
    "\n",
    "$$u_\\text{direct}(\\tau, \\mu, \\phi) = I_0 \\delta(\\mu - \\mu_0) \\delta(\\phi - \\phi_0) \\exp\\left(-\\mu_{0}^{-1} \\tau\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403129c6",
   "metadata": {},
   "source": [
    "**IMPORTANT:** Note that `PyDISORT` will output the **diffuse intensity** and the **total flux**. One will need to separately add the intensity of the direct beam to get the total intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99ba1a",
   "metadata": {},
   "source": [
    "# 1. USER INPUT REQUIRED: List of parameters to set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d7d98",
   "metadata": {},
   "source": [
    "Note that for many parameters we are able to adjust the code to accomodate a wider range of values. Doing that, however, would slow-down and convolute the code. These special cases should also rarely arise in physical models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d52f3ac",
   "metadata": {},
   "source": [
    "## 1.1 Hyperparameter list (excludes phase function) (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27764183",
   "metadata": {},
   "source": [
    "The variable names generally follow those in Stamnes et. al.'s seminal 1988 paper [[1]](#cite-STWJ1988), with the equivalent variable in their DISORT code [[2]](#cite-Sta1999) in brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10e74f",
   "metadata": {},
   "source": [
    "* Optical depth (DTAUC), i.e. bottom of atmosphere as we define the top to be $\\tau = 0$. We implemented the scaling method in [[3]](#cite-SC1984) to prevent ill-conditioning when $\\tau_0 > 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f555ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau0 = (25 / 8) * (10**-2)  # There may be ill-conditioning if tau0 > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7cb9f8",
   "metadata": {},
   "source": [
    "* Single-scattering albedo (SSALB). We assume independence from $\\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1154a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3ecf9",
   "metadata": {},
   "source": [
    "The permissible range of values is $[0,1)$, values too close to $1$ will cause instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28ffcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert w0 >= 0\n",
    "assert w0 < 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2926d",
   "metadata": {},
   "source": [
    "* Parameters for the incident collimated beam. The flux contribution of this beam is $I_0 \\mu_0$. Note that we do not allow $\\mu_0$ to equal a quadrature / computational angle and `PyDISORT` will check for this; this is consistent with Stamnes' DISORT [[1]](#cite-STWJ1988)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "52dafd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intensity (FBEAM)\n",
    "I0 = 10 * pi\n",
    "# Cosine of polar angle (UMU0)\n",
    "mu0 = pi / 4\n",
    "# Azimuthal angle (PHI0)\n",
    "phi0 = pi / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b01491",
   "metadata": {},
   "source": [
    "We do not allow `mu0` to be less than or equal to $0$; `PyDISORT` is not designed to model a beam shining up from the surface into the bottom of the atmosphere. We also require the angles to be principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12caf2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 < mu0 and mu0 < 1\n",
    "assert 0 < phi0 and phi0 < 2 * pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b83a4",
   "metadata": {},
   "source": [
    " * Dirichlet boundary conditions (No direct equivalent in Stamnes' DISORT [[2]](#cite-Sta1999), but see variable *IBCND*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a7466",
   "metadata": {},
   "source": [
    "$$\n",
    "u\\left(\\tau_0, \\mu_i, \\phi \\right) = \\sum_{m = 0}^{\\text{NLeg}}b^+_{im}\\cos(m(\\phi_0 - \\phi)), \\quad u(0, -\\mu_i, \\phi) = \\sum_{m = 0}^{\\text{NLeg}}b^-_{im}\\cos(m(\\phi_0 - \\phi)) \\quad i = 1, \\dots, N\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ebabb5",
   "metadata": {},
   "source": [
    "where $b^\\pm$ are to be specified, and variables `NLeg` and $N$ are specified further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c2bd769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should actually be matrices with row index i and column index m,\n",
    "# but it is ok for them to be a constant.\n",
    "# Do NOT input a vector,\n",
    "# while we can implement code to accomodate vector inputs it would be unnecessarily confusing.\n",
    "\n",
    "# At bottom of atmosphere\n",
    "b_pos = 0\n",
    "\n",
    "# At top of atmosphere\n",
    "b_neg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef686f",
   "metadata": {},
   "source": [
    "* Whether to only compute flux values (ONLYFL). If `True`, `PyDISORT` will be much faster because we will only need to solve the $0$th Fourier mode integro-differential equation, see sections [3.7.3](#3.7.3-Computation-of-flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1330118",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_flux = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855af7bc",
   "metadata": {},
   "source": [
    "## 1.2 Computational variable list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b1f84",
   "metadata": {},
   "source": [
    "* Number of Legendre coefficients for the phase function (NMOM). Equal to the number of Fourier modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d329e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLeg = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d51344",
   "metadata": {},
   "source": [
    "* Number of evaluation points for quadrature approximation of the polar or $\\mu$ integral (NSTR). This parameter is also known as the number of \"streams\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70938256",
   "metadata": {},
   "outputs": [],
   "source": [
    "NQuad = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8566fa0",
   "metadata": {},
   "source": [
    "`NQuad` is required to be greater than $2$, even, and less than or equal to `NLeg`. It is generally a good idea to have `NQuad == NLeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98ff8911",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert NQuad > 2\n",
    "assert NQuad % 2 == 0\n",
    "assert NQuad <= NLeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c51440",
   "metadata": {},
   "source": [
    "We define $N = \\text{NQuad} \\ / \\ 2$. This variable will be used extensively later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7873aa19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NQuad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3076\\1079999973.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This will be used later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNQuad\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'NQuad' is not defined"
     ]
    }
   ],
   "source": [
    "N = NQuad // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19572ec",
   "metadata": {},
   "source": [
    "Each BC input must be a scalar or a matrix of dimension $N \\times \\text{NLeg}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbaccafc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'fill'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3076\\2403586862.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This ensures that the BC inputs are of the correct shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mb_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNLeg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_pos\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNLeg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[0;32m    312\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'fill'"
     ]
    }
   ],
   "source": [
    "# This ensures that the BC inputs are of the correct shape\n",
    "if len(np.atleast_1d(b_pos)) == 1:\n",
    "    b_pos = np.fill(b_pos, (N, NLeg))\n",
    "else:\n",
    "    assert np.shape(b_pos) == (N, NLeg)\n",
    "if len(np.atleast_1d(b_neg)) == 1:\n",
    "    b_neg = np.fill(b_neg, (N, NLeg))\n",
    "else:\n",
    "    assert np.shape(b_neg) == (N, NLeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f834616",
   "metadata": {},
   "source": [
    "## 1.3 Legendre expansion of the phase function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d5c631",
   "metadata": {},
   "source": [
    "Following the method in [[1]](#cite-STWJ1988) but with slightly different notations and definitions, we expand the phase function\n",
    "\n",
    "$$\n",
    "p(\\cos\\gamma) \\approx \\sum_{\\ell=0} g_\\ell P_\\ell(\\cos\\gamma), \\quad g_\\ell = \\frac{2\\ell + 1}{2}\\int_{-1}^{1} p(\\cos\\gamma) P_\\ell(\\cos\\gamma) \\mathrm{d}\\cos\\gamma\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05020faa",
   "metadata": {},
   "source": [
    "The angle $\\gamma$ is between the incident vector $\\left(\\theta', \\phi'\\right)$ and the scattering vector $(\\theta, \\phi)$ such that\n",
    "\n",
    "$$\n",
    "\\cos\\gamma = \\cos\\theta'\\cos\\theta + \\sin\\theta'\\sin\\theta\\cos\\left(\\phi'-\\phi\\right)\n",
    "$$\n",
    "\n",
    "and so by the addition theorem for spherical harmonics\n",
    "\n",
    "$$\n",
    "P_\\ell(\\cos\\gamma) = P_\\ell\\left(\\cos\\theta'\\right)P_\\ell(\\cos\\theta) + 2\\sum_{m=1}^\\ell \\frac{(\\ell-m)!}{(\\ell+m)!}P_\\ell^m\\left(\\cos\\theta'\\right)P_\\ell^m(\\cos\\theta)\\cos\\left(m\\left(\\phi'-\\phi\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d29fc7",
   "metadata": {},
   "source": [
    "### 1.3.1 Phase functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843eb5b7",
   "metadata": {},
   "source": [
    "Phase functions in Stamnes' DISORT [[2]](#cite-Sta1999):\n",
    "* Isotropic\n",
    "* Rayleigh\n",
    "* Henyey-Greenstein with asymmetry factor\n",
    "* Haze L as specified by Garcia/Siewert\n",
    "* Cloud C.1 as specified by Garcia/Siewert\n",
    "* Aerosol as specified by Kokhanovsky \n",
    "* Cloud as specified by Kokhanovsky"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04bb03",
   "metadata": {},
   "source": [
    "**Henyey-Greenstein phase function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d17ec",
   "metadata": {},
   "source": [
    "The exact definition varies between sources by a constant factor. The definition here follows [[1]](#cite-STWJ1988), though the phase function is not explicitly defined in that paper:\n",
    "\n",
    "$$\\frac{1-g^2}{\\left(1+g^2-2 g \\cos \\gamma\\right)^{3 / 2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55f15d",
   "metadata": {},
   "source": [
    "* Asymmetry factor (GG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62297c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb51c848",
   "metadata": {},
   "source": [
    "* Phase function\n",
    "\n",
    "`p_HG_nu` is equivalent to `p_HG` except that it uses $\\nu = \\cos\\gamma$. `p_HG_muphi` is also equivalent except that it uses\n",
    "\n",
    "\\begin{aligned}\n",
    "\\cos\\gamma &= \\cos\\theta'\\cos\\theta + \\sin\\theta'\\sin\\theta\\cos\\left(\\phi'-\\phi\\right) \\\\\n",
    "&= \\mu'\\mu + \\sqrt{1 - \\mu'^2}\\sqrt{1 - \\mu^2}\\cos\\left(\\phi'-\\phi\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "with $\\mu = \\cos\\theta$, $\\mu' = \\cos\\theta'$; see [[6]](#cite-MW1980) but note that we place $\\omega_0$ outside our phase function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31dcb77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_HG = lambda gamma: (1 - g**2) / ((1 + g**2 - 2 * g * np.cos(gamma)) ** (3 / 2))\n",
    "p_HG_nu = lambda nu: (1 - g**2) / ((1 + g**2 - 2 * g * nu) ** (3 / 2))\n",
    "\n",
    "def p_HG_muphi(mu, phi, mu_p, phi_p):\n",
    "    mu, phi, mu_p, phi_p = np.atleast_1d(mu, phi, mu_p, phi_p)\n",
    "    return np.squeeze(\n",
    "        (1 - g**2)\n",
    "        / (\n",
    "            1\n",
    "            + g**2\n",
    "            - 2\n",
    "            * g\n",
    "            * np.moveaxis(\n",
    "                np.outer(mu, mu_p)[:, :, None, None]\n",
    "                + np.tensordot(\n",
    "                    np.outer(np.sqrt(1 - mu**2), np.sqrt(1 - mu_p**2)),\n",
    "                    np.cos(phi[:, None] - phi_p[None, :]),\n",
    "                    axes=0,\n",
    "                ),\n",
    "                source=(2, 1),\n",
    "                destination=(1, 2),\n",
    "            )\n",
    "        )\n",
    "        ** (3 / 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b14d0e",
   "metadata": {},
   "source": [
    "* Normalized array of $g_\\ell$ values $\\big((2\\ell + 1) \\times \\text{PMOM}\\big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4216352",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_arr = np.arange(NLeg)\n",
    "Leg_coeffs = (2 * m_arr) * g**m_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aff355",
   "metadata": {},
   "source": [
    "* True phase function with vector arguments $\\mu, \\phi, \\mu', \\phi'$ for use in Nakajima-Tanaka corrections, see section [3.7.1](#3.7.1-Nakajima-Tanaka-%28NT%29-corrections-%28TODO%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1115298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_for_NT_cor = p_HG_muphi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61337052",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(signature(p_for_NT_cor).parameters) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c41735",
   "metadata": {},
   "source": [
    "**Integral derivation of Legendre coefficients for verification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb74d3",
   "metadata": {},
   "source": [
    "[Skip verification](#1.3.2-$\\delta-M$-scaled-Legendre-coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec4f8c5",
   "metadata": {},
   "source": [
    "This algorithm can be used to derive the Legendre coefficients for other phase functions. The algorithm can also be vectorized, but we would no longer be able to use `scipy.integrate.quad` for integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30c7248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all tests\n"
     ]
    }
   ],
   "source": [
    "Leg_coeffs_test = np.empty(NLeg)\n",
    "for ell in range(NLeg):\n",
    "    integrand = lambda nu: p_HG_nu(nu) * legendre.Legendre(np.append(np.zeros(ell), 1))(nu)\n",
    "    Leg_coeffs_test[ell] = ((2 * ell + 1) / 2) * integrate.quad(integrand, -1, 1)[0]\n",
    "\n",
    "assert np.allclose(Leg_coeffs, Leg_coeffs_test)\n",
    "\n",
    "print(\"Passed all tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4868357a",
   "metadata": {},
   "source": [
    "### 1.3.2 $\\delta-M$ scaled Legendre coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a4325a",
   "metadata": {},
   "source": [
    "Standard Legendre series approximation of highly anisotropic phase functions require a large number of terms to accurately capture their strong directional scattering. The Henyey-Greenstein phase function, for example, is strongly forward scattering. We can use fewer Legendre terms if we re-express the phase function as a linear combination of a $\\delta$-function and an (approximately) isotropic remainder. We follow the method in [[5]](#cite-Wis1977) for scaling the first $2M$ Legendre coefficients of a phase function such that they become the coefficients of the isotropic remainder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5735d",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&p(\\cos \\gamma) \\approx 2 f \\delta(1-\\cos \\gamma) + (1 - f) \\sum_{\\ell=0}^{2 M-1} (2 \\ell+1) g_\\ell^* P_\\ell(\\cos \\gamma), \\quad g^*_\\ell = \\frac{g_\\ell - f}{1 - f} \\\\\n",
    "&\\iff p(\\mu, \\phi; \\mu', \\phi') \\approx 4 \\pi f \\delta(\\mu - \\mu')\\delta(\\phi - \\phi') + (1 - f) p^*(\\mu, \\phi; \\mu', \\phi')\n",
    "\\end{aligned}\n",
    "\n",
    "where $\\mu = \\cos\\theta$, $\\mu' = \\cos\\theta'$, and $f \\in [0, 1)$ is to be chosen ($f = 0$ is equivalent to no $\\delta-M$ scaling). The first $2M$ Legendre coefficients of this re-expression will agree with those of the phase function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bf3743",
   "metadata": {},
   "source": [
    "We generally choose $f = g_{2M} = g_\\text{NLeg}$ so that the scaled Legendre series is equivalent to the standard Legendre series in the limit $M \\rightarrow \\infty$. An implication of this is that $\\delta-M$ scaling is unimpactful for large $M$, which is desirable. This choice of $f$ with $M = 1$ is equivalent to the delta-Eddington method, see [[4]](#cite-JWW1976). We discuss the impact of this phase function re-expression on the radiative transfer equation in section [2.3.2](#3.3-$\\delta-M$-scaling-in-the-Radiative-Transfer-Equation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e172a8e",
   "metadata": {},
   "source": [
    "The flag to enable $\\delta-M$ scaling is `f > 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962f6f2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NLeg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16916\\2342201818.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mNLeg\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mNLeg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'NLeg' is not defined"
     ]
    }
   ],
   "source": [
    "f = (2 * NLeg) * g**NLeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 <= f and f < 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2882ef4f",
   "metadata": {},
   "source": [
    "# 2. PyDISORT algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21530f1e",
   "metadata": {},
   "source": [
    "[Skip section](#3.-Breakdown-and-verification-of-single-layer-solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181cfd40",
   "metadata": {},
   "source": [
    "## 2.1 Subroutines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e48d1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the D term in the system of ODEs\n",
    "def generate_Ds(m):\n",
    "    ells = np.arange(m, NLeg)\n",
    "    Dm_term = Leg_coeffs[ells] * (\n",
    "        sc.special.factorial(ells - m) / sc.special.factorial(ells + m)\n",
    "    )\n",
    "\n",
    "    degree_tile = np.tile(ells, (N, 1)).T\n",
    "    asso_leg_term_pos = sc.special.lpmv(m, degree_tile, mu_arr_pos)\n",
    "    asso_leg_term_neg = sc.special.lpmv(m, degree_tile, mu_arr_neg)\n",
    "    # We use broadcasting instead of diagonal matrices for computational efficiency\n",
    "    D_temp = (Dm_term)[None, :] * asso_leg_term_pos.T\n",
    "\n",
    "    D_pos = (w0 / 2) * D_temp @ asso_leg_term_pos\n",
    "    D_neg = (w0 / 2) * D_temp @ asso_leg_term_neg\n",
    "\n",
    "    return D_pos, D_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X term in the system of ODEs\n",
    "def generate_Xs(m):\n",
    "    if m == 0:\n",
    "        prefactor = w0 * I0 / (4 * pi)\n",
    "    else:\n",
    "        prefactor = w0 * I0 / (2 * pi)\n",
    "\n",
    "    ells = np.arange(m, NLeg)\n",
    "    Xm_term = Leg_coeffs[ells] * (\n",
    "        sc.special.factorial(ells - m) / sc.special.factorial(ells + m)\n",
    "    )\n",
    "    Xm_term2 = sc.special.lpmv(m, ells, -mu0)\n",
    "    X_temp = prefactor * Xm_term * Xm_term2\n",
    "\n",
    "    degree_tile = np.tile(ells, (N, 1)).T\n",
    "    X_pos = X_temp @ sc.special.lpmv(m, degree_tile, mu_arr_pos)\n",
    "    X_neg = X_temp @ sc.special.lpmv(m, degree_tile, mu_arr_neg)\n",
    "\n",
    "    return X_pos, X_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12895810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the up and down flux functions\n",
    "def create_flux_functions(\n",
    "    I0, mu0, GC_pos, GC_neg, eigenvals, B_pos, B_neg, scale_tau, scale_beam\n",
    "):\n",
    "    def flux_up(tau):\n",
    "        # Delta-M scaling\n",
    "        tau = scale_tau * np.atleast_1d(tau)\n",
    "        um = GC_pos @ np.exp(np.outer(eigenvals, tau)) + np.outer(\n",
    "            B_pos, np.exp(-tau / mu0)\n",
    "        )\n",
    "        return np.squeeze(2 * pi * (mu_arr_pos * weights) @ um)\n",
    "\n",
    "    def flux_down(tau):\n",
    "        # Delta-M scaling\n",
    "        tau = scale_tau * np.atleast_1d(tau)\n",
    "        um = GC_neg @ np.exp(np.outer(eigenvals, tau)) + np.outer(\n",
    "            B_neg, np.exp(-tau / mu0)\n",
    "        )\n",
    "        return np.squeeze(\n",
    "            2 * pi * (mu_arr_pos * weights) @ um\n",
    "        ) + scale_beam * I0 * mu0 * np.exp(-tau / mu0)\n",
    "\n",
    "    return flux_up, flux_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453dff34",
   "metadata": {},
   "source": [
    "## 2.2 Main algorithms (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d958f8c2",
   "metadata": {},
   "source": [
    "*TODO: Implement solver for multiple atmospheric layers as well as multi-layer scaling from [[3]](#cite-SC1984)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155a342",
   "metadata": {},
   "source": [
    "*TODO: Add more explanation and comments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "339f1c6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (523006624.py, line 101)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\dionh\\AppData\\Local\\Temp\\ipykernel_3076\\523006624.py\"\u001b[1;36m, line \u001b[1;32m101\u001b[0m\n\u001b[1;33m    return np.squeeze(2 * pi * (mu_arr_pos * weights) @ um) + direct flux\u001b[0m\n\u001b[1;37m                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def main(b_pos, b_neg,\n",
    "         only_flux,\n",
    "         N, NQuad, NLeg,\n",
    "         mu_arr_pos, mu_arr_neg, weights,\n",
    "         tau0, w0, Leg_coeffs,\n",
    "         mu0, phi0, I0, \n",
    "         scale_tau, scale_beam,\n",
    "):  # This function has many redundant arguments to maximize precomputation in the wrapper function\n",
    "\n",
    "    # If we want to solve for the intensity we need to solve for NLeg Fourier modes\n",
    "    # If we only want to solve for the flux we only need to solve for the 0th Fourier mode\n",
    "    if not only_flux:\n",
    "        GC_collect = np.empty((NQuad, NQuad, NLeg))\n",
    "        eigenvals_collect = np.empty((NQuad, NLeg))\n",
    "        B_collect = np.empty((NQuad, NLeg))\n",
    "\n",
    "    not_complex = True\n",
    "    for m in range(NLeg):\n",
    "        D_pos, D_neg = generate_Ds(m)\n",
    "        # We use broadcasting instead of diagonal matrices for computational efficiency\n",
    "        M_inv = 1 / mu_arr_pos\n",
    "        W = weights[None, :]\n",
    "        alpha = M_inv[:, None] * (D_pos * W - np.eye(N))\n",
    "        beta = M_inv[:, None] * D_neg * W\n",
    "        A = np.vstack((np.hstack((-alpha, -beta)), np.hstack((beta, alpha))))\n",
    "\n",
    "        eigenvals_squared, eigenvecs_GpG = np.linalg.eig(\n",
    "            (alpha - beta) @ (alpha + beta)\n",
    "        )\n",
    "        eigenvals = np.concatenate(\n",
    "            (\n",
    "                np.sqrt(eigenvals_squared.astype(complex)),\n",
    "                -np.sqrt(eigenvals_squared.astype(complex)),\n",
    "            )\n",
    "        )\n",
    "        # The eigenvalues are often, but not always real. It is more computationally efficient to work with real values.\n",
    "        # Since the matrix is real, we can obtain a real eigenvector if the corresponding eigenvalue is real, and\n",
    "        # the eigenvector will be complex if the corresponding eigenvalue is complex.\n",
    "        if np.allclose(np.imag(eigenvals), 0):\n",
    "            eigenvals = np.real(eigenvals)\n",
    "        elif not_complex and not only_flux:\n",
    "            eigenvals_collect = eigenvals_collect.astype(complex)\n",
    "            GC_collect = GC_collect.astype(complex)\n",
    "            not_complex = False\n",
    "\n",
    "        eigenvecs_GpG = np.hstack((eigenvecs_GpG, eigenvecs_GpG))\n",
    "        eigenvecs_GmG = (alpha + beta) @ eigenvecs_GpG / -eigenvals\n",
    "\n",
    "        G_pos = (eigenvecs_GpG + eigenvecs_GmG) / 2\n",
    "        G_neg = (eigenvecs_GpG - eigenvecs_GmG) / 2\n",
    "        G = np.vstack((G_pos, G_neg))\n",
    "\n",
    "        X_pos, X_neg = generate_Xs(m)\n",
    "        X_tilde = np.concatenate((-M_inv * X_pos, M_inv * X_neg))\n",
    "\n",
    "        B = np.linalg.solve(-(np.eye(NQuad) / mu0 + A), X_tilde)\n",
    "        B_pos, B_neg = B[:N], B[N:]\n",
    "        Dk_tau0 = np.exp(eigenvals * tau0)\n",
    "\n",
    "        LHS = np.vstack((G_pos * Dk_tau0[None, :], G_neg))\n",
    "        RHS = np.concatenate(\n",
    "            (b_pos[:, m] - B_pos * np.exp(-tau0 / mu0), b_neg[:, m] - B_neg)\n",
    "        )\n",
    "        C = np.linalg.solve(LHS, RHS)\n",
    "\n",
    "        if only_flux:\n",
    "            return create_flux_functions(\n",
    "                I0,\n",
    "                mu0,\n",
    "                G_pos * C[None, :],\n",
    "                G_neg * C[None, :],\n",
    "                eigenvals,\n",
    "                B_pos,\n",
    "                B_neg,\n",
    "                scale_tau,\n",
    "                scale_beam,\n",
    "            )\n",
    "\n",
    "        GC_collect[:, :, m] = G * C[None, :]\n",
    "        eigenvals_collect[:, m] = eigenvals\n",
    "        B_collect[:, m] = B\n",
    "\n",
    "    def u(tau, phi):\n",
    "        # Delta-M scaling\n",
    "        tau = scale_tau * np.atleast_1d(tau)\n",
    "\n",
    "        # um must be real; the second term is already real\n",
    "        um = np.real(\n",
    "            np.einsum(\n",
    "                \"ijm, jmt -> imt\",\n",
    "                GC_collect,\n",
    "                np.exp(np.tensordot(eigenvals_collect, tau, axes=0)),\n",
    "                optimize=True,\n",
    "            )\n",
    "        ) + np.tensordot(B_collect, np.exp(-tau / mu0), axes=0)\n",
    "\n",
    "        return np.squeeze(\n",
    "            np.tensordot(um, np.cos(np.outer(np.arange(NLeg), phi0 - phi)), axes=(1, 0))\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        u,\n",
    "        create_flux_functions(\n",
    "            I0,\n",
    "            mu0,\n",
    "            GC_collect[:N, :, 0],\n",
    "            GC_collect[N:, :, 0],\n",
    "            eigenvals_collect[:, 0],\n",
    "            B_collect[:N, 0],\n",
    "            B_collect[N:, 0],\n",
    "            scale_tau,\n",
    "            scale_beam,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1c49a",
   "metadata": {},
   "source": [
    "### 2.2.1 Call PyDISORT (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0850f",
   "metadata": {},
   "source": [
    "*TODO: Implement IMS intensity correction*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956803e9",
   "metadata": {},
   "source": [
    "*TODO: Implement / tweak tests for NT corrected intensities*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fb157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyDISORT(\n",
    "    b_pos, b_neg, only_flux, NQuad, tau0, w0, Leg_coeffs, mu0, phi0, I0, f=0, p_for_NT_cor=None,\n",
    "):  # The argument order approximately follows that of Stamnes' DISORT\n",
    "\n",
    "    # INPUT CHECKS\n",
    "    # -----------------------------------------------------------\n",
    "    NLeg = len(Leg_coeffs)\n",
    "    # The scattering fraction must be greater than or equal to 0 and less than 1\n",
    "    assert 0 <= f and f < 1\n",
    "    # We require principal angles and a downward beam\n",
    "    assert 0 < mu0 and mu0 < 1\n",
    "    assert 0 < phi0 and phi0 < 2 * pi\n",
    "    # We require NQuad to be >2, even, and <= NLeg\n",
    "    assert NQuad > 2\n",
    "    assert NQuad % 2 == 0\n",
    "    assert NQuad <= NLeg\n",
    "\n",
    "    N = NQuad // 2\n",
    "    # The following ensures that the BC inputs are of the correct shape\n",
    "    if len(np.atleast_1d(b_pos)) == 1:\n",
    "        b_pos = np.fill(b_pos, (N, NLeg))\n",
    "    else:\n",
    "        assert np.shape(b_pos) == (N, NLeg)\n",
    "    if len(np.atleast_1d(b_neg)) == 1:\n",
    "        b_neg = np.fill(b_neg, (N, NLeg))\n",
    "    else:\n",
    "        assert np.shape(b_neg) == (N, NLeg)\n",
    "    # -----------------------------------------------------------\n",
    "\n",
    "    # For positive mu values (the weights are identical for both domains)\n",
    "    mu_arr_pos, weights = legendre.leggauss(N)\n",
    "    mu_arr_pos = mu_arr_pos * (1 / 2) + (1 / 2)\n",
    "    weights = weights / 2\n",
    "    # For negative mu values\n",
    "    mu_arr_neg = -mu_arr_pos\n",
    "    # We do not allow mu0 to equal a quadrature / computational angle\n",
    "    assert not np.any(np.isclose(mu_arr_pos, mu0))\n",
    "\n",
    "    # Delta-M scaling; there is no scaling if f == 0\n",
    "    scale_tau = 1 - w0 * f\n",
    "    scale_beam = 1 + w0 * f\n",
    "    Leg_coeffs = (Leg_coeffs - f) / (1 - f)\n",
    "    w0 *= (1 - f) / scale_tau\n",
    "    tau0 *= scale_tau\n",
    "\n",
    "    # Perform NT correction on the intensity but not the flux\n",
    "    if callable(p_for_NT_cor) and not only_flux:\n",
    "        assert len(signature(p_for_NT_cor).parameters) == 4\n",
    "        \n",
    "        u_star, flux_up, flux_down = main(\n",
    "            b_pos, b_neg,\n",
    "            only_flux,\n",
    "            N, NQuad, NLeg,\n",
    "            tau0, w0, Leg_coeffs,\n",
    "            mu0, phi0, I0,\n",
    "            scale_tau, scale_beam,\n",
    "        )\n",
    "        \n",
    "        # This is the source term for the NT correction single-scattering equation\n",
    "        def mathcal_B(tau, mu_arr, phi, tilde):\n",
    "            if tilde:\n",
    "                w0 /= 1 - f\n",
    "            return (\n",
    "                ((w0 * I0) / (4 * np.pi))\n",
    "                * p_for_NT_cor(mu_arr, phi, -mu0, phi0)\n",
    "                * np.exp(-tau / mu0)\n",
    "                / (mu_arr / mu0 + 1)\n",
    "            )\n",
    "\n",
    "        # NT correction for the intensity\n",
    "        def u_star1(tau, phi, tilde):\n",
    "            tau = scale_tau * np.atleast_1d(tau)\n",
    "            u_star1_pos = -B(tau, mu_arr_pos, phi, tilde) * (\n",
    "                np.exp(np.tensordot(tau, mu_arr_pos, axes=0))\n",
    "                - np.exp(-tau / mu0)[:, None]\n",
    "            )\n",
    "            u_star1_neg = -B(tau, mu_arr_neg, phi, tilde) * (\n",
    "                np.exp(tau0 * (1 / mu_arr_pos - 1 / mu0))\n",
    "                * np.exp(np.tensordot(tau, mu_arr_neg, axes=0))\n",
    "                - np.exp(-tau / mu0)[:, None]\n",
    "            )\n",
    "            return u_star1_pos, u_star1_neg\n",
    "\n",
    "        u_output = lambda tau, phi: np.squeeze(\n",
    "            u_star(tau, phi) - u_star1(tau, phi, False) + u_star1(tau, phi, True)\n",
    "        )\n",
    "        return np.concatenate((mu_arr_pos, mu_arr_neg)), u_output, flux_up, flux_down\n",
    "        \n",
    "    else:\n",
    "        return np.concatenate((mu_arr_pos, mu_arr_neg)), main(\n",
    "            b_pos, b_neg,\n",
    "            only_flux,\n",
    "            N, NQuad, NLeg,\n",
    "            tau0, w0, Leg_coeffs,\n",
    "            mu0, phi0, I0,\n",
    "            scale_tau, scale_beam,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdfd5bc",
   "metadata": {},
   "source": [
    "# 3. Breakdown and verification of single layer solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4f605",
   "metadata": {},
   "source": [
    "In this section we breakdown and explain the code for solving the radiative transfer equation for a single atmospheric layer. Unless otherwise stated, we will take $\\delta-M$ scaling to be disabled (`f == 0`) and we will not apply Nakajima-Tanaka intensity corrections (`callable(p_for_NT_cor) == True`). We will explain $\\delta-M$ scaling and Nakajima-Tanaka corrections in their independent sections. We begin with some quadrature algorithms that we will need later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df50562e",
   "metadata": {},
   "source": [
    "## 3.1 Quadrature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29043208",
   "metadata": {},
   "source": [
    "Generation of Gauss-Legendre quadrature weights and points to numerically integrate over $\\mu$ from $-1$ to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "180909f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For positive mu values (the weights are identical for both domains)\n",
    "mu_arr_pos, weights = legendre.leggauss(N)\n",
    "mu_arr_pos = mu_arr_pos * (1 / 2) + (1 / 2)\n",
    "weights = weights / 2\n",
    "\n",
    "# For negative mu values\n",
    "mu_arr_neg = -mu_arr_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f993c0fb",
   "metadata": {},
   "source": [
    "Algorithm to generate Clenshaw-Curtis quadrature weights and points for numerical integration over $\\phi$. Required for tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50ac9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clenshaw_Curtis_quad(Nphi, a=0, b=2 * pi):\n",
    "    # Ensure that the number of nodes is odd and greater than 2\n",
    "    assert Nphi > 2\n",
    "    assert Nphi % 2 == 1\n",
    "\n",
    "    Nphi -= 1  # The extra index corresponds to the point 0 which we will add later\n",
    "    Nphi_pos = Nphi // 2\n",
    "    phi_arr_pos = np.cos(pi * np.arange(Nphi_pos) / Nphi)\n",
    "    phi_arr = np.hstack((phi_arr_pos, 0, -phi_arr_pos))\n",
    "    d = np.hstack((2, 2 / (1 - 4 * np.arange(1, Nphi_pos + 1) ** 2)))\n",
    "    pos_weights_phi = sc.fft.idct(d, type=1)\n",
    "    pos_weights_phi[0] /= 2\n",
    "    full_weights_phi = np.hstack((pos_weights_phi, pos_weights_phi[:-1]))\n",
    "    \n",
    "    return phi_arr * ((b - a) / 2) + ((b + a) / 2), full_weights_phi * ((b - a) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ee345",
   "metadata": {},
   "source": [
    "### 3.1.1 Verification of quadrature weights and points on test integral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a278019",
   "metadata": {},
   "source": [
    "[Skip verifications](#3.2-Re-derivation-of-equations-%286a%29-to-%286d%29-in-Stamnes-et.-al.,-1988)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d2874",
   "metadata": {},
   "source": [
    "$$\\int_{a}^{b} e^x \\ \\mathrm{d}x = e^b - e^a$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a8926fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauss-Legendre quadrature % error = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Gauss-Legendre quadrature; integrate from -1 to 1\n",
    "mu_arr = np.concatenate((mu_arr_pos, mu_arr_neg))\n",
    "full_weights_mu = np.concatenate((weights, weights))\n",
    "true_sol = np.exp(1) - np.exp(-1)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Gauss-Legendre quadrature % error =\",\n",
    "    np.abs((true_sol - np.sum(np.exp(mu_arr) * full_weights_mu)) / true_sol),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f449ffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clenshaw-Curtis quadrature % error = 2.1270086547936496e-16\n"
     ]
    }
   ],
   "source": [
    "# Clenshaw-Curtis quadrature; integrate from 0 to 2pi\n",
    "phi_arr, full_weights_phi = Clenshaw_Curtis_quad(33)\n",
    "true_sol = np.exp(2*pi) - 1\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Clenshaw-Curtis quadrature % error =\",\n",
    "    np.abs((true_sol - np.sum(np.exp(phi_arr) * full_weights_phi)) / true_sol),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0df06",
   "metadata": {},
   "source": [
    "### 3.1.2 Normalization verification of the phase function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441203c1",
   "metadata": {},
   "source": [
    "Similar to equation (2) of [[6]](#cite-MW1980), we expect\n",
    "\n",
    "$$\n",
    "\\frac{1}{4 \\pi} \\int_{-1}^1 \\int_0^{2 \\pi} p\\left(\\mu, \\phi ; \\mu^{\\prime}, \\phi^{\\prime}\\right) d \\phi d \\mu = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7c23464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_inf % error = 0.062211405074487525\n"
     ]
    }
   ],
   "source": [
    "# We verify the HG phase function\n",
    "phi_arr, full_weights_phi = Clenshaw_Curtis_quad(33)\n",
    "mu_arr = np.concatenate((mu_arr_pos, mu_arr_neg))\n",
    "full_weights_mu = np.concatenate((weights, weights))\n",
    "\n",
    "normalize_pHG = np.tensordot(\n",
    "    np.tensordot(\n",
    "        p_HG_muphi(mu_arr, phi_arr, mu_arr, phi_arr), full_weights_mu, axes=(0, 0)\n",
    "    ),\n",
    "    full_weights_phi,\n",
    "    axes=(0, 0),\n",
    ") / (4 * pi)\n",
    "\n",
    "\n",
    "print(\"L_inf % error =\", np.linalg.norm(normalize_pHG - 1, ord=np.infty))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b135f22",
   "metadata": {},
   "source": [
    "## 3.2 Re-derivation of equations (6a) to (6d) in Stamnes et. al., 1988"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81279f",
   "metadata": {},
   "source": [
    "[[1]](#cite-STWJ1988)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a99d371",
   "metadata": {},
   "source": [
    "We have the definitions and expansions\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "u\\left(\\tau, \\mu, \\phi\\right) &\\approx \\sum_{n=0} u^n\\left(\\tau, \\mu\\right)\\cos\\left(n\\left(\\phi_0 - \\phi\\right)\\right) \\quad \\text{(Fourier cosine expansion)}\\\\\n",
    "p\\left(\\cos\\gamma\\right) &\\approx \\sum_{\\ell=0} g_\\ell P_\\ell\\left(\\cos\\gamma\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "g_\\ell &= \\frac{2\\ell + 1}{2}\\int_{-1}^{1} p\\left(\\cos\\gamma\\right) P_\\ell\\left(\\cos\\gamma\\right) \\mathrm{d}\\cos\\gamma, \\quad &&g_\\ell^m = \\frac{\\left(\\ell-m\\right)!}{\\left(\\ell+m\\right)!} g_\\ell \\\\\n",
    "\\mu &= \\cos\\left(\\theta\\right), \\quad &&\\,\\mu' = \\cos\\left(\\theta'\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "As before, we have\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\cos\\gamma &= \\cos\\theta'\\cos\\theta + \\sin\\theta'\\sin\\theta\\cos\\left(\\phi'-\\phi\\right) \\\\\n",
    "P_\\ell\\left(\\cos\\gamma\\right) &= P_\\ell\\left(\\mu'\\right)P_\\ell\\left(\\mu\\right) + 2\\sum_{m=1}^\\ell \\frac{\\left(\\ell-m\\right)!}{\\left(\\ell+m\\right)!}P_\\ell^m(\\mu')P_\\ell^m\\left(\\mu\\right)\\cos\\left(m\\left(\\phi'-\\phi\\right)\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Consequently, we can expand the `p_HG_muphi` form of the HG phase function\n",
    "\n",
    "$$\n",
    "p\\left(\\mu, \\phi; \\mu', \\phi'\\right) \\approx \\sum_{\\ell=0} \\left[ g_\\ell P_\\ell\\left(\\mu'\\right)P_\\ell\\left(\\mu\\right) + 2\\sum_{m=1}^\\ell g_\\ell^m P_\\ell^m(\\mu')P_\\ell^m\\left(\\mu\\right)\\cos\\left(m\\left(\\phi'-\\phi\\right)\\right) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d8d22",
   "metadata": {},
   "source": [
    "We will first focus on the **double integral term** of the radiative transfer equation. We substitute the expansion of $p(\\mu, \\phi; \\mu', \\phi')$ and $u(\\tau, \\mu, \\phi)$ to get\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\frac{\\omega_0}{4 \\pi} \\int_{-1}^{1} \\int_{0}^{2 \\pi} p\\left(\\mu, \\phi ; \\mu', \\phi'\\right) u\\left(\\tau, \\mu', \\phi'\\right) \\mathrm{d} \\phi' \\mathrm{d} \\mu' \\\\\n",
    "&\\approx \\frac{\\omega_0}{4 \\pi} \\int_{-1}^{1} \\left[ \\int_{0}^{2 \\pi} \\sum_{n=0} \\sum_{\\ell=0} u^n g_\\ell P_\\ell\\left(\\mu'\\right)P_\\ell(\\mu) \\cos\\left(n\\left(\\phi_0 - \\phi'\\right)\\right) + 2\\sum_{n=0} \\sum_{\\ell=0} \\sum_{m=1}^\\ell u^n g_\\ell^m P_\\ell^m(\\mu')P_\\ell^m(\\mu)\\cos\\left(m\\left(\\phi'-\\phi\\right)\\right) \\cos\\left(n\\left(\\phi_0 - \\phi'\\right)\\right) \\mathrm{d} \\phi' \\right] \\mathrm{d} \\mu' \\\\\n",
    "&= \\frac{\\omega_0}{4 \\pi} \\int_{-1}^{1} \\left[ \\int_{0}^{2 \\pi} \\sum_{\\ell=0} u^0 g_\\ell P_\\ell\\left(\\mu'\\right)P_\\ell(\\mu) + 2\\sum_{n=1} \\sum_{\\ell=n} \\sum_{m=1}^\\ell u^n g_\\ell^m P_\\ell^m(\\mu')P_\\ell^m(\\mu)\\cos\\left(m\\left(\\phi'-\\phi\\right)\\right) \\cos\\left(n\\left(\\phi_0 - \\phi'\\right)\\right) \\mathrm{d} \\phi' \\right] \\mathrm{d} \\mu' \\\\\n",
    "&= \\frac{\\omega_0}{4 \\pi} \\int_{-1}^{1} \\left[ 2\\pi \\sum_{\\ell=0} u^0 g_\\ell P_\\ell\\left(\\mu'\\right)P_\\ell(\\mu) + 2\\pi\\sum_{n=1} \\sum_{\\ell=n} u^n g_\\ell^n P_\\ell^n(\\mu')P_\\ell^n(\\mu)\\cos\\left(n\\left(\\phi_0 - \\phi\\right)\\right) \\right] \\mathrm{d} \\mu' \\\\\n",
    "&= \\int_{-1}^{1} \\sum_{m=0} \\left\\{ \\frac{\\omega_0}{2} \\sum_{\\ell=m} u^m g_\\ell^m P_\\ell^m(\\mu')P_\\ell^m(\\mu) \\right\\} \\cos\\left(m\\left(\\phi_0 - \\phi\\right)\\right) \\mathrm{d} \\mu'\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The term in the curly brackets of the last line is the contribution of the double-integral term to the $m$th Fourier moment of the radiative transfer equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4332606f",
   "metadata": {},
   "source": [
    "Next, we will focus on the **source term**. Once again, we substitute the expansion of $p(\\mu, \\phi; \\mu', \\phi')$ to get\n",
    "\n",
    "$$\n",
    "\\frac{\\omega_0 I_0}{4 \\pi} p\\left(\\mu, \\phi ;-\\mu_{0}, \\phi_{0}\\right) \\exp\\left(-\\mu_{0}^{-1} \\tau\\right) \\approx \\frac{\\omega_0 I_0}{4 \\pi} \\exp\\left(-\\mu_{0}^{-1} \\tau\\right) \\left[ \\sum_{\\ell=0} g_\\ell P_\\ell\\left(-\\mu_0\\right)P_\\ell(\\mu) + 2\\sum_{\\ell=0}\\sum_{m=1}^\\ell g_\\ell^m P_\\ell^m\\left(-\\mu_0\\right)P_\\ell^m(\\mu)\\cos\\left(m\\left(\\phi_0-\\phi\\right)\\right) \\right]\n",
    "$$\n",
    "\n",
    "It is immediately apparent that the contribution to the $0$th moment is\n",
    "\n",
    "$$\n",
    "\\frac{\\omega_0 I_0}{4 \\pi} \\exp\\left(-\\mu_{0}^{-1} \\tau\\right)\\sum_{\\ell=0} g_\\ell P_\\ell\\left(-\\mu_0\\right)P_\\ell(\\mu)\n",
    "$$\n",
    "\n",
    "For $n \\geq 1$, to determine the contribution to the $n$th moment, we multiply by $\\pi^{-1}\\cos\\left(n\\left(\\phi_0-\\phi\\right)\\right)$ and integrate over $\\phi$ from $0$ to $2\\pi$ to get\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\frac{\\omega_0 I_0}{4 \\pi} \\exp\\left(-\\mu_{0}^{-1} \\tau\\right) \\int_{0}^{2\\pi} \\frac{2}{\\pi}\\sum_{\\ell=0}\\sum_{m=1}^\\ell g_\\ell^m P_\\ell^m\\left(-\\mu_0\\right)P_\\ell^m(\\mu)\\cos\\left(m\\left(\\phi_0-\\phi\\right)\\right)\\cos\\left(n\\left(\\phi_0-\\phi\\right)\\right) \\mathrm{d}\\phi \\\\\n",
    "&= \\frac{\\omega_0 I_0}{4 \\pi} \\exp\\left(-\\mu_{0}^{-1} \\tau\\right) \\int_{0}^{2\\pi} \\frac{2}{\\pi}\\sum_{\\ell=n}\\sum_{m=1}^\\ell g_\\ell^m P_\\ell^m\\left(-\\mu_0\\right)P_\\ell^m(\\mu)\\cos\\left(m\\left(\\phi_0-\\phi\\right)\\right)\\cos\\left(n\\left(\\phi_0-\\phi\\right)\\right) \\mathrm{d}\\phi \\\\\n",
    "&= \\frac{\\omega_0 I_0}{2 \\pi} \\exp\\left(-\\mu_{0}^{-1} \\tau\\right) \\sum_{\\ell=n} g_\\ell^n P_\\ell^n\\left(-\\mu_0\\right)P_\\ell^n(\\mu)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Therefore, the contribution of the source term to the $m$th Fourier moment of the radiative transfer equation (we perform the change of variables $m = n$) is\n",
    "\n",
    "$$\n",
    "\\kappa_m\\exp\\left(-\\mu_{0}^{-1} \\tau\\right)\\sum_{\\ell=0} g^m_\\ell P_\\ell^m\\left(-\\mu_0\\right)P_\\ell^m(\\mu), \\quad \\kappa_m = \\begin{cases} \\frac{\\omega_0 I_0}{4 \\pi}, &m = 0 \\\\ \\frac{\\omega_0 I_0}{2 \\pi}, &m \\geq 1 \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe996aec",
   "metadata": {},
   "source": [
    "Consequently, for each Fourier mode, $m \\geq 0$, we have the integro-differential equation\n",
    "\n",
    "$$\n",
    "\\mu \\frac{d u^m(\\tau, \\mu)}{d \\tau}=u^m(\\tau, \\mu)-\\int_{-1}^1 D^m\\left(\\tau, \\mu, \\mu^{\\prime}\\right) u^m\\left(\\tau, \\mu^{\\prime}\\right) d \\mu^{\\prime} - Q^m(\\mu)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D^m\\left(\\mu, \\mu' \\right) &= \\frac{\\omega_0}{2} \\sum_{\\ell=m} u^m g_\\ell^m P_\\ell^m(\\mu')P_\\ell^m(\\mu) \\\\\n",
    "Q^m(\\mu) &= X^m(\\mu) \\exp\\left(-\\mu_{0}^{-1} \\tau\\right) \\\\\n",
    "X^m(\\mu) &= \\kappa_m\\sum_{\\ell=0} g^m_\\ell P_\\ell^m\\left(-\\mu_0\\right)P_\\ell^m(\\mu), \\quad \\kappa_m = \\begin{cases} \\frac{\\omega_0 I_0}{4 \\pi}, &m = 0 \\\\ \\frac{\\omega_0 I_0}{2 \\pi}, &m \\geq 1 \\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Unlike in [[1]](#cite-STWJ1988), our source term, $Q$, only contains the \"beam\" term and not a \"thermal\" term. It is also only dependent on $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99355f",
   "metadata": {},
   "source": [
    "### 3.2.1 Verification of subroutines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c737b",
   "metadata": {},
   "source": [
    "[Skip verifications](#3.3-$\\delta-M$-scaling-in-the-Radiative-Transfer-Equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ee287",
   "metadata": {},
   "source": [
    "**This is the non-vectorized version of the `generate_Ds` subroutine for verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d01e4f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all tests\n"
     ]
    }
   ],
   "source": [
    "for m in range(NLeg):\n",
    "    D_pos_test, D_neg_test = np.zeros((N, N)), np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for ell in range(m, NLeg):\n",
    "                D_pos_test[i, j] += (\n",
    "                    (w0 / 2)\n",
    "                    # * (2 * ell + 1) # Moved into the main algorithm\n",
    "                    * Leg_coeffs[ell]\n",
    "                    * (sc.special.factorial(ell - m) / sc.special.factorial(ell + m))\n",
    "                    * sc.special.lpmv(m, ell, mu_arr_pos[i])\n",
    "                    * sc.special.lpmv(m, ell, mu_arr_pos[j])\n",
    "                )\n",
    "                D_neg_test[i, j] += (\n",
    "                    (w0 / 2)\n",
    "                    # * (2 * ell + 1) # Moved into the main algorithm\n",
    "                    * Leg_coeffs[ell]\n",
    "                    * (sc.special.factorial(ell - m) / sc.special.factorial(ell + m))\n",
    "                    * sc.special.lpmv(m, ell, mu_arr_neg[i])\n",
    "                    * sc.special.lpmv(m, ell, mu_arr_pos[j])\n",
    "                )\n",
    "\n",
    "                \n",
    "    assert np.allclose(D_pos_test, generate_Ds(m)[0])\n",
    "    assert np.allclose(D_neg_test, generate_Ds(m)[1])\n",
    "print(\"Passed all tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81bde95",
   "metadata": {},
   "source": [
    "**This is the non-vectorized version of the `generate_Xs` subroutine (for the non-trivial case $m = 0$) for verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9566866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all tests\n"
     ]
    }
   ],
   "source": [
    "for m in range(NLeg):\n",
    "    if m == 0:\n",
    "        prefactor = w0 * I0 / (4 * pi)\n",
    "    else:\n",
    "        prefactor = w0 * I0 / (2 * pi)\n",
    "    X_pos_test, X_neg_test = np.zeros(N), np.zeros(N)\n",
    "    for i in range(N):\n",
    "        for ell in range(m, NLeg):\n",
    "            X_pos_test[i] += (\n",
    "                prefactor\n",
    "                * Leg_coeffs[ell]\n",
    "                * (sc.special.factorial(ell - m) / sc.special.factorial(ell + m))\n",
    "                * sc.special.lpmv(m, ell, -mu0)\n",
    "                * sc.special.lpmv(m, ell, mu_arr_pos[i])\n",
    "            )\n",
    "            X_neg_test[i] += (\n",
    "                prefactor\n",
    "                * Leg_coeffs[ell]\n",
    "                * (sc.special.factorial(ell - m) / sc.special.factorial(ell + m))\n",
    "                * sc.special.lpmv(m, ell, -mu0)\n",
    "                * sc.special.lpmv(m, ell, mu_arr_neg[i])\n",
    "            )\n",
    "\n",
    "            \n",
    "    assert np.allclose(X_pos_test, generate_Xs(m)[0])\n",
    "    assert np.allclose(X_neg_test, generate_Xs(m)[1])\n",
    "print(\"Passed all tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d6e98b",
   "metadata": {},
   "source": [
    "## 3.3 $\\delta-M$ scaling in the Radiative Transfer Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a99d60e",
   "metadata": {},
   "source": [
    "Substitute the truncated, $\\delta-M$ approximated phase function\n",
    "\n",
    "$$\n",
    "p(\\mu, \\phi; \\mu', \\phi') = 4 \\pi f \\delta(\\mu - \\mu')\\delta(\\phi - \\phi') + (1 - f) p^*(\\mu, \\phi; \\mu', \\phi')\n",
    "$$\n",
    "\n",
    "into the radiative transfer equation to get\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mu \\frac{\\partial u(\\tau, \\mu, \\phi)}{\\partial \\tau} = \\ &(1 - \\omega_0 f) u(\\tau, \\mu, \\phi) -\\frac{(1 - f)\\omega_0}{4 \\pi} \\int_{-1}^{1} \\int_{0}^{2 \\pi} p^*\\left(\\mu, \\phi ; \\mu', \\phi'\\right) u\\left(\\tau, \\mu', \\phi'\\right) \\mathrm{d} \\phi' \\mathrm{d} \\mu' \\\\\n",
    "&-\\omega_0 I_0 \\left(f \\delta(\\mu - \\mu_0)\\delta(\\phi - \\phi_0) + \\frac{1 - f}{4 \\pi} p^*\\left(\\mu, \\phi ;-\\mu_{0}, \\phi_{0}\\right)\\right) \\exp\\left(-\\mu_{0}^{-1} \\tau\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "We shift the $\\delta$-function term to the **direct** beam to get\n",
    "\n",
    "$$u^*_\\text{direct} = (1 + \\omega_0 f) I_0 \\delta(\\mu - \\mu_0)\\delta(\\phi - \\phi_0) \\exp\\left(-\\mu_{0}^{-1} \\tau\\right)$$\n",
    "\n",
    "For the remaining **diffuse** intensity, which we denote $u^*$, we perform the change of variables\n",
    "\n",
    "$$\\tau^* = (1 - \\omega_0 f) \\tau \\iff \\frac{\\mathrm{d}\\tau}{\\mathrm{d}\\tau^*} = (1 - \\omega_0 f)^{-1}, \n",
    "\\quad \\omega^*_0 = \\frac{1-f}{1 - \\omega_0 f} \\omega_0$$\n",
    "\n",
    "to get\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mu \\frac{\\partial u^*(\\tau^*, \\mu, \\phi)}{\\partial \\tau^*} = u^*(\\tau^*, \\mu, \\phi) &-\\frac{\\omega^*_0}{4 \\pi} \\int_{-1}^{1} \\int_{0}^{2 \\pi} p^*\\left(\\mu, \\phi ; \\mu', \\phi'\\right) u^*\\left(\\tau^*, \\mu', \\phi'\\right) \\mathrm{d} \\phi' \\mathrm{d} \\mu' \\\\\n",
    "&-\\frac{\\omega^*_0 I_0}{4 \\pi} p^*\\left(\\mu, \\phi ;-\\mu_{0}, \\phi_{0}\\right) \\exp\\left(-\\mu_{0}^{-1} \\tau\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "which is in the exact same form as the radiative transfer equation for $u$, but with $\\tau$, $\\omega_0$, $p$ swapped for $\\tau^*$, $\\omega^*_0$, $p^*$ respectively. Note that the total intensity is unchanged with\n",
    "\n",
    "$$u_\\text{total} = u^* + u^*_\\text{direct}$$\n",
    "\n",
    "See [[5]](#cite-Wis1977) for more details on $\\delta-M$ scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e4ec46",
   "metadata": {},
   "source": [
    "## 3.4 Re-derivation of equations (7a) and (7b) in Stamnes et. al., 1988"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b8abf",
   "metadata": {},
   "source": [
    "[[1]](#cite-STWJ1988)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54087f37",
   "metadata": {},
   "source": [
    "We split the $\\mu$ integral into two integrals: from $-1$ to $0$ and from $0$ to $1$. We approximate each integral by Gauss-Legendre quadrature. This is the *double-Gauss method*; see [[7]](#cite-Syk1951) for more details. By double-Gauss, or any other double quadrature method (more general quadrature methods can be used, but we will lose important symmetries), we can approximate each Fourier mode integro-differential equation as\n",
    "\n",
    "\n",
    "$$\n",
    "\\mu_i \\frac{d u^m(\\tau, \\mu_i)}{d \\tau}=u^m(\\tau, \\mu_i)-\\sum_{j \\neq 0} w_j D^m\\left(\\tau, \\mu_i, \\mu_i^{\\prime}\\right) u^m\\left(\\tau, \\mu_i^{\\prime}\\right) d \\mu_i^{\\prime} - Q^m(\\mu_i)\n",
    "$$\n",
    "\n",
    "For $i,j = 1, \\dots, N$, where $2N$ is the number of quadrature points, we define\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\alpha = M^{-1}\\left(D^{+} W - I\\right) &&\\beta = M^{-1} D^{-} W \\\\\n",
    "&D^{+}[i,j] = D^m\\left(\\mu_i, \\mu_j\\right) = D^m\\left(-\\mu_i,-\\mu_j\\right) &&D^{-}[i,j] = D^m\\left(-\\mu_i, \\mu_j\\right) = D^m\\left(\\mu_i,-\\mu_j\\right) \\\\\n",
    "&W[i,j] = w_i\\delta_{ij} &&M[i,j] = \\mu_i\\delta_{ij} \\\\ \n",
    "&u^\\pm[i] = u^m(\\pm \\mu_i) &&Q^{\\pm}[i] = Q^m\\left(\\pm \\mu_i\\right) \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We also define $\\tilde{Q}^\\pm = M^{-1} Q^\\pm$. We claim that the Fourier mode approximations can be re-expressed as the system\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\frac{\\mathrm{d}u^+}{\\mathrm{d}\\tau} \\\\ \\frac{\\mathrm{d}u^-}{\\mathrm{d}\\tau} \\end{bmatrix} = \\begin{bmatrix} -\\alpha & -\\beta \\\\ \\beta & \\alpha \\end{bmatrix} \\begin{bmatrix} u^+ \\\\ u^- \\end{bmatrix} + \\begin{bmatrix} -\\tilde{Q}^+ \\\\ \\tilde{Q}^- \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cb7bab",
   "metadata": {},
   "source": [
    "Substitute $\\alpha, \\beta, \\tilde{Q}$ on the RHS:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix} -\\alpha & -\\beta \\\\ \\beta & \\alpha \\end{bmatrix} \\begin{bmatrix} u^+ \\\\ u^- \\end{bmatrix} + \\begin{bmatrix} -\\tilde{Q}^+ \\\\ \\tilde{Q}^- \\end{bmatrix} &= \\begin{bmatrix} -M^{-1}\\left(D^{+} W - I\\right) & -M^{-1} D^{-} W \\\\ M^{-1} D^{-} W & M^{-1}\\left(D^{+} W - I\\right) \\end{bmatrix} \\begin{bmatrix} u^+ \\\\ u^- \\end{bmatrix} + \\begin{bmatrix} -M^{-1} Q^+ \\\\ M^{-1} Q^- \\end{bmatrix} \\\\\n",
    "&= \\begin{bmatrix} -M^{-1} & \\\\ & M^{-1} \\end{bmatrix} \\left( \\begin{bmatrix} D^{+} W - I & D^{-} W \\\\ D^{-} W & D^{+} W - I \\end{bmatrix} \\begin{bmatrix} u^+ \\\\ u^- \\end{bmatrix} + \\begin{bmatrix} Q^+ \\\\ Q^- \\end{bmatrix} \\right) \\\\\n",
    "&= \\begin{bmatrix} -\\mu_0^{-1} & & & & & \\\\ & \\ddots & & & & \\\\ & & -\\mu_N^{-1} & & & \\\\ & & & \\mu_0^{-1} & & \\\\ & & & & \\ddots & \\\\ & & & & & \\mu_N^{-1} \\end{bmatrix} \\left( \\left( \\begin{bmatrix} D^{+} W & D^{-} W \\\\ D^{-} W & D^{+} W \\end{bmatrix} - I \\right) \\begin{bmatrix} u^+ \\\\ u^- \\end{bmatrix} + \\begin{bmatrix} Q^+ \\\\ Q^- \\end{bmatrix} \\right) \\\\\n",
    "&= \\begin{bmatrix} \\mu_0^{-1} & & & & & \\\\ & \\ddots & & & & \\\\ & & \\mu_N^{-1} & & & \\\\ & & & -\\mu_0^{-1} & & \\\\ & & & & \\ddots & \\\\ & & & & & -\\mu_N^{-1} \\end{bmatrix} \\left(\\begin{bmatrix} u^+ \\\\ u^- \\end{bmatrix} - W \\begin{bmatrix} D^{+} & D^{-} \\\\ D^{-} & D^{+} \\end{bmatrix} - \\begin{bmatrix} Q^+ \\\\ Q^- \\end{bmatrix} \\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Finally, we multiply across by the $\\mu_i$ values to see that the system is consistent with the Fourier mode approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc6e0a3",
   "metadata": {},
   "source": [
    "## 3.5 Solving the system for each Fourier mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bcb1df",
   "metadata": {},
   "source": [
    "As previously derived, the system is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beec0ff",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix} \\frac{\\mathrm{d}u^+}{\\mathrm{d}\\tau} \\\\ \\frac{\\mathrm{d}u^-}{\\mathrm{d}\\tau} \\end{bmatrix} = \\begin{bmatrix} -\\alpha & -\\beta \\\\ \\beta & \\alpha \\end{bmatrix} \\begin{bmatrix} u^+ \\\\ u^- \\end{bmatrix} + \\begin{bmatrix} -\\tilde{Q}^+ \\\\ \\tilde{Q}^- \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9f00b",
   "metadata": {},
   "source": [
    "Define $\\tilde{Q} = \\begin{bmatrix} -\\tilde{Q}^+ \\tilde{Q}^- \\end{bmatrix}^T$ and $\\tilde{X} = \\exp\\left(\\mu_0^{-1} \\tau\\right)\\tilde{Q}$. We first address the homogeneous problem, when $\\tilde{Q} = 0$, and solve for the eigenpairs of the coefficient matrix from the eigenequation\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} -\\alpha & -\\beta \\\\ \\beta & \\alpha \\end{bmatrix} \\begin{bmatrix} G^+ \\\\ G^- \\end{bmatrix} = k \\begin{bmatrix} G^+ \\\\ G^- \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3ccdb",
   "metadata": {},
   "source": [
    "Following the reduction order method in [[1]](#cite-STWJ1988), but with minor sign differences, we can solve\n",
    "\n",
    "$$\n",
    "(\\alpha - \\beta) (\\alpha + \\beta) \\left(G^+ + G^-\\right) = k^2 \\left(G^+ + G^-\\right)\n",
    "$$\n",
    "\n",
    "for eigenvalues $k$. Given also that\n",
    "\n",
    "$$\n",
    "(\\alpha + \\beta) \\left(G^+ + G^-\\right) = -k \\left(G^+ - G^-\\right)\n",
    "$$\n",
    "\n",
    "we can solve for $G^+$ and $G^-$, and consequently construct the eigenvector matrix $G = \\begin{bmatrix} G^+ & G^- \\end{bmatrix}^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d12c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3  # We will need to repeat the following blocks of code for each Fourier mode, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88ec4674",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_pos, D_neg = generate_Ds(m)\n",
    "# We use broadcasting instead of diagonal matrices for computational efficiency\n",
    "M_inv = 1 / mu_arr_pos\n",
    "W = weights[None, :]\n",
    "alpha = M_inv[:, None] * (D_pos * W - np.eye(N))\n",
    "beta = M_inv[:, None] * D_neg * W\n",
    "A = np.vstack((np.hstack((-alpha, -beta)), np.hstack((beta, alpha))))\n",
    "\n",
    "eigenvals_squared, eigenvecs_GpG = np.linalg.eig((alpha - beta) @ (alpha + beta))\n",
    "eigenvals = np.concatenate(\n",
    "    (\n",
    "        np.sqrt(eigenvals_squared.astype(complex)),\n",
    "        -np.sqrt(eigenvals_squared.astype(complex)),\n",
    "    )\n",
    ")\n",
    "# The eigenvalues are often, but not always real. It is more computationally efficient to work with real values.\n",
    "# Since the matrix is real, we can obtain a real eigenvector if the corresponding eigenvalue is real, and\n",
    "# the eigenvector will be complex if the corresponding eigenvalue is complex.\n",
    "if np.allclose(np.imag(eigenvals), 0):\n",
    "    eigenvals = np.real(eigenvals)\n",
    "\n",
    "eigenvecs_GpG = np.hstack((eigenvecs_GpG, eigenvecs_GpG))\n",
    "eigenvecs_GmG = (alpha + beta) @ eigenvecs_GpG / -eigenvals\n",
    "\n",
    "G_pos = (eigenvecs_GpG + eigenvecs_GmG) / 2\n",
    "G_neg = (eigenvecs_GpG - eigenvecs_GmG) / 2\n",
    "G = np.vstack((G_pos, G_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2ffd0",
   "metadata": {},
   "source": [
    "**Verification of eigenpairs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291151f2",
   "metadata": {},
   "source": [
    "[Skip verification](#3.6-Constructing-the-general-solution-for-each-Fourier-mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32f6cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all tests\n"
     ]
    }
   ],
   "source": [
    "assert np.allclose((A @ G) / eigenvals, G)\n",
    "print(\"Passed all tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dbd535",
   "metadata": {},
   "source": [
    "## 3.6 Constructing the general solution for each Fourier mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e92478e",
   "metadata": {},
   "source": [
    "For each Fourier mode, $m$, the general solution is\n",
    "\n",
    "$$\n",
    "u^m = v^m + w^m\n",
    "$$\n",
    "\n",
    "where $v$, $w$ denotes the homogeneous and particular solutions respectively. We will omit the superscript $m$ going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9edc1",
   "metadata": {},
   "source": [
    "### 3.6.1 The particular solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09957a31",
   "metadata": {},
   "source": [
    "The particular solution, $v$, satisfies\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d}v}{\\mathrm{d}\\tau} = A v + \\tilde{Q}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} -\\alpha & -\\beta \\\\ \\beta & \\alpha \\end{bmatrix}, \\quad \\tilde{Q} = \\tilde{X} \\exp\\left(-\\mu_0^{-1} \\tau\\right)\n",
    "$$\n",
    "\n",
    "Assume the ansatz\n",
    "\n",
    "$$\n",
    "v = B\\exp\\left(-\\mu_0^{-1} \\tau\\right)\n",
    "$$\n",
    "\n",
    "for $B$ to be determined. Substitution into the full equation gives\n",
    "\n",
    "\\begin{aligned}\n",
    "&-\\mu_0^{-1} B\\exp\\left(-\\mu_0^{-1} \\tau\\right) = AB\\exp\\left(-\\mu_0^{-1} \\tau\\right) + \\tilde{X}\\exp\\left(-\\mu_0^{-1} \\tau\\right) \\\\\n",
    "&\\implies -\\mu_0^{-1} B = AB + \\tilde{X} \\\\\n",
    "&\\implies -\\left(\\mu_0^{-1} I + A\\right)B = \\tilde{X}\n",
    "\\end{aligned}\n",
    "\n",
    "which we can solve for $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d1e398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos, X_neg = generate_Xs(m)\n",
    "X_tilde = np.concatenate((-M_inv * X_pos, M_inv * X_neg))\n",
    "\n",
    "B = np.linalg.solve(-(np.eye(NQuad) / mu0 + A), X_tilde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db54cc",
   "metadata": {},
   "source": [
    "**Verification of particular solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c3e08",
   "metadata": {},
   "source": [
    "[Skip verification](#3.6.2-The-homogeneous-solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3ae9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntau = 2**9  # Number of tau grid points\n",
    "tau_arr = np.linspace(0, tau0, Ntau)\n",
    "h = tau_arr[1] - tau_arr[0]  # grid spacing\n",
    "\n",
    "# Construct 1st derivative matrix with 2nd order accuracy\n",
    "first_deriv = np.zeros((Ntau, Ntau))\n",
    "diagonal = np.ones(Ntau) / (2 * h)\n",
    "first_deriv += np.diag(diagonal[:-1], 1)\n",
    "first_deriv += np.diag(-diagonal[:-1], -1)\n",
    "first_deriv[0, :3] = np.array([-3 / 2, 2, -1 / 2]) / h\n",
    "first_deriv[-1, -3:] = np.array([1 / 2, -2, 3 / 2]) / h\n",
    "first_deriv = first_deriv.T # This is due to tau being indexed by columns instead of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db1069c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointwise L_inf % error: 1.3009691165637128e-07\n"
     ]
    }
   ],
   "source": [
    "up = np.outer(B, np.exp(-tau_arr / mu0))\n",
    "RHS = up @ first_deriv\n",
    "LHS = A @ up + np.outer(X_tilde, np.exp(-tau_arr / mu0))\n",
    "\n",
    "\n",
    "print(\"Pointwise L_inf % error:\", np.linalg.norm((RHS - LHS) / RHS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245b434",
   "metadata": {},
   "source": [
    "### 3.6.2 The homogeneous solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6071b2",
   "metadata": {},
   "source": [
    "The homogeneous solution (vector), $w$, can be split into\n",
    "\n",
    "$$\n",
    "w = \\begin{bmatrix} w^+ \\\\ w^- \\end{bmatrix}, \\quad  w^\\pm(\\tau) = G^\\pm \\text{Diag}(C) K\n",
    "$$\n",
    "\n",
    "where $K[j] = \\exp(k_j\\tau)$ and the coefficient vector $C$ is to be determined from the boundary conditions. We define $\\tau \\in [0, \\tau_0]$ and assume Dirichlet BCs (more general BCs are possible but not implemented)\n",
    "\n",
    "$$\n",
    "w^-(0) = b^-_m, \\quad w^+\\left( \\tau_0 \\right) = b^+_m\n",
    "$$\n",
    "\n",
    "where $b^\\pm_m$ is the $m$th column of $b^\\pm$; recall that we are solving for the $m$th Fourier mode. By superposition,\n",
    "\n",
    "$$\n",
    "w^-(0) = b^-_m - B^-, \\quad w^+\\left( \\tau_0 \\right) = b^+_m - B^+\\exp\\left(-\\mu_0^{-1} \\tau_0\\right)\n",
    "$$\n",
    "\n",
    "and this produces the system\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} G^+ D_k\\left( \\tau_0 \\right) \\\\ G^- \\end{bmatrix} C = \\begin{bmatrix} b^+_m - B^+\\exp\\left(-\\mu_0^{-1} \\tau_0\\right) \\\\ b^-_m - B^- \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "which we can solve to determine $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acad8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_pos, B_neg = B[:N], B[N:]\n",
    "Dk_tau0 = np.exp(eigenvals * tau0)\n",
    "\n",
    "LHS = np.vstack((G_pos * Dk_tau0[None, :], G_neg))\n",
    "RHS = np.concatenate((b_pos[:, m] - B_pos * np.exp(-tau0 / mu0), b_neg[:, m] - B_neg))\n",
    "C = np.linalg.solve(LHS, RHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6093190e",
   "metadata": {},
   "source": [
    "### 3.6.3 Verification of the general solution for one Fourier mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aad9af",
   "metadata": {},
   "source": [
    "[Skip verification](#3.7-The-full-solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e28b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The general solution for one Fourier mode\n",
    "def um(tau):\n",
    "    result = (G * C[None, :]) @ np.exp(np.outer(eigenvals, tau)) + np.outer(\n",
    "        B, np.exp(-tau / mu0)\n",
    "    )\n",
    "\n",
    "    # The general solution must be real\n",
    "    assert np.allclose(np.imag(result), 0)\n",
    "    return np.real(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f9a98b",
   "metadata": {},
   "source": [
    "**Does the general solution satisfy the BCs?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5db8eb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all tests\n"
     ]
    }
   ],
   "source": [
    "# At top of atmosphere\n",
    "assert np.allclose(um(0)[N:], b_neg)\n",
    "\n",
    "# At bottom of atmosphere\n",
    "assert np.allclose(um(tau0)[:N], b_pos)\n",
    "print(\"Passed all tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55085c43",
   "metadata": {},
   "source": [
    "**Does the general solution satisfy the system of ODEs?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fbc7e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointwise L_inf % error: 0.026988727349968232\n"
     ]
    }
   ],
   "source": [
    "um_cache = um(tau_arr)\n",
    "RHS = um_cache @ first_deriv\n",
    "LHS = A @ um_cache + np.outer(X_tilde, np.exp(-tau_arr / mu0))\n",
    "\n",
    "\n",
    "print(\"Pointwise L_inf % error:\", np.linalg.norm((RHS - LHS) / RHS, ord=np.infty))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4376cf8",
   "metadata": {},
   "source": [
    "**Does the general solution satisfy the Fourier mode integro-differential equation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddbcdb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointwise L_inf % error: 0.026988727349061378\n"
     ]
    }
   ],
   "source": [
    "D = np.hstack((np.vstack((D_pos, D_neg)), np.vstack((D_neg, D_pos))))\n",
    "RHS = mu_arr[:, None] * um(tau_arr) @ first_deriv\n",
    "LHS = (\n",
    "    um_cache\n",
    "    - np.tensordot(\n",
    "        np.einsum(\"ij, jt -> ijt\", D, um_cache, optimize=True),\n",
    "        full_weights_mu,\n",
    "        axes=(1, 0),\n",
    "    )\n",
    "    - np.outer(np.concatenate((X_pos, X_neg)), np.exp(-tau_arr / mu0))\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Pointwise L_inf % error:\", np.linalg.norm((RHS - LHS) / RHS, ord=np.infty))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7394658b",
   "metadata": {},
   "source": [
    "## 3.7 The full solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a49a51",
   "metadata": {},
   "source": [
    "The above must be repeated for each Fourier mode. The full numerical solution given by `PyDISORT` is\n",
    "\n",
    "$$\n",
    "u(\\tau, \\mu, \\phi) = \\sum_{m=0} u^m(\\mu,\\tau)\\cos\\left(m\\left(\\phi_0 - \\phi\\right)\\right)\n",
    "$$\n",
    "\n",
    "This solution is continuous and variable with respect to $\\tau$ and $\\phi$ but discrete and fixed with respect to $\\mu$. The function output is 3-dimensional and axes $0, 1, 2$ capture $\\mu, \\tau, \\phi$ variation respectively. The solution $u$ is easily split into $u^+$ and $u^-$ by halving the $\\mu$ index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee15761a",
   "metadata": {},
   "source": [
    "**IMPORTANT:** reminder that `PyDISORT` will output the **diffuse intensity** and the **total flux**. One will need to separately / manually add the intensity of the direct beam to get the total intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86ecace",
   "metadata": {},
   "source": [
    "### 3.7.1 Nakajima-Tanaka (NT) corrections (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64918ae",
   "metadata": {},
   "source": [
    "This subsection summarizes the main points from [[8]](#cite-NT1988) and omits most of the mathematical explanation. Recall that $\\tau^*, \\omega^*_0, p^*$ denote $\\delta-M$ scaled parameters and $f$ is the scattering fraction. Note that we require the true phase function with vector arguments $\\mu, \\phi, \\mu', \\phi'$ supplied through the variable `p_for_NT_cor` to perform NT corrections. The flag to enable NT corrections is `callable(p_for_NT_cor)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b6904",
   "metadata": {},
   "source": [
    "The $\\delta-M$ method allows for accurate flux computation, but intensity values remain inaccurate particularly at very small or very large scattering angles with respect to the direct beam. This is caused by the truncation of the Legendre series of the phase function. Nakajima and Tanaka use perturbation theory to reduce the truncation error. This correction is applied to the intensity but not to the flux as the latter is already accurate. This unfortunately means that flux values calculated by integrating the intensity will differ slightly from values given by the flux functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c58c24",
   "metadata": {},
   "source": [
    "We denote the radiative transfer equation with a general source function $J$,\n",
    "\n",
    "$$\n",
    "\\mu \\frac{\\partial u(\\tau, \\mu, \\phi)}{\\partial \\tau} = u(\\tau, \\mu, \\phi) -\\frac{\\omega_0}{4 \\pi} \\int_{-1}^{1} \\int_{0}^{2 \\pi} p\\left(\\mu, \\phi ; \\mu', \\phi'\\right) u\\left(\\tau, \\mu', \\phi'\\right) \\mathrm{d} \\phi' \\mathrm{d} \\mu' - J\n",
    "$$\n",
    "\n",
    "by the functional notation $\\mathcal{F}(u, \\tau, \\omega_0, p; J)$. For example, the original radiative transfer is denoted\n",
    "\n",
    "$$\\mathcal{F}\\left(u, \\tau, \\omega_0, p; \\frac{\\omega_0 I_0}{4 \\pi} p\\left(\\mu, \\phi ;-\\mu_{0}, \\phi_{0}\\right) \\exp\\left(-\\mu_{0}^{-1} \\tau\\right)\\right)$$\n",
    "\n",
    "using this notation. The NT correction method can be considered an extension of the $\\delta-M$ method. For the $\\delta-M$ method, we approximate $u_\\text{true} \\approx u^*$\n",
    "where $u_\\text{true}$ is the true solution to the original radiative transfer equation, and $u^*$ is the true solution to \n",
    "\n",
    "$$\\mathcal{F}\\left(u^*, \\tau^*, \\omega^*_0, p^*; \\frac{\\omega^*_0 I_0}{4 \\pi} p^*\\left(\\mu, \\phi ;-\\mu_{0}, \\phi_{0}\\right) \\exp\\left(-\\mu_{0}^{-1} \\tau^*\\right)\\right)$$\n",
    "\n",
    "We can only determine $u^*$ up to some numerical error. This numerical error comes from the eigenvalue solver, quadrature, linear system solver and so on, but does not come from truncation. There is no truncation since $p^*$ is defined as a truncated phase function and we use every term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1b162",
   "metadata": {},
   "source": [
    "For the first of two NT corrections, named *TMS*, we approximate $u_\\text{true} \\approx u_\\text{TMS} := u^* - u_1^* + \\tilde{u}_1^*$, where $u_1^*$ and $\\tilde{u}_1^*$ are true solutions to the single-scattering equations\n",
    "\n",
    "$$\\mathcal{F}\\left(u_1^*, \\tau^*, 0, 0; \\frac{\\omega^*_0 I_0}{4 \\pi} p\\left(\\mu, \\phi ;-\\mu_{0}, \\phi_{0}\\right) \\exp\\left(-\\mu_{0}^{-1} \\tau^*\\right)\\right), \\quad \\mathcal{F}\\left(\\tilde{u}_1^*, \\tau^*, 0, 0; \\frac{\\omega^*_0 I_0}{(1 - f) 4 \\pi} p\\left(\\mu, \\phi ;-\\mu_{0}, \\phi_{0}\\right) \\exp\\left(-\\mu_{0}^{-1} \\tau^*\\right)\\right)$$\n",
    "\n",
    "respectively. By the principle of superposition, every correction term, i.e. every term but $u^*$, must satisfy homogeneous BCs. We can solve for $u_1^*$ and $\\tilde{u}_1^*$ analytically:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "u_1^*(\\tau^*, \\mu_i, \\phi) &= -\\mathcal{B}(\\tau^*, \\mu_i, \\phi)\\left[\\exp\\left(\\frac{\\tau^*}{\\mu_i}\\right) - \\exp\\left(-\\frac{\\tau^*}{\\mu_0}\\right)\\right] \\\\\n",
    "u_1^*(\\tau^*, -\\mu_i, \\phi) &= -\\mathcal{B}(\\tau^*, -\\mu_i, \\phi)\\left[\\exp\\left(\\tau^*_0\\left(\\frac{1}{\\mu_i} - \\frac{1}{\\mu_0}\\right)\\right)\\exp\\left(-\\frac{\\tau^*}{\\mu_i}\\right) - \\exp\\left(-\\frac{\\tau^*}{\\mu_0}\\right)\\right] \\\\\n",
    "\\tilde{u}_1^*(\\tau^*, \\mu_i, \\phi) &= -\\tilde{\\mathcal{B}}(\\tau^*, \\mu_i, \\phi)\\left[\\exp\\left(\\frac{\\tau^*}{\\mu_i}\\right) - \\exp\\left(-\\frac{\\tau^*}{\\mu_0}\\right)\\right] \\\\\n",
    "\\tilde{u}_1^*(\\tau^*, -\\mu_i, \\phi) &= -\\tilde{\\mathcal{B}}(\\tau^*, -\\mu_i, \\phi)\\left[\\exp\\left(\\tau^*_0\\left(\\frac{1}{\\mu_i} - \\frac{1}{\\mu_0}\\right)\\right)\\exp\\left(-\\frac{\\tau^*}{\\mu_i}\\right) - \\exp\\left(-\\frac{\\tau^*}{\\mu_0}\\right)\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{B}(\\tau^*, \\pm\\mu_i, \\phi) &= \\left(\\pm \\frac{\\mu_i}{\\mu_0} + 1 \\right)^{-1} \\frac{\\omega^*_0 I_0}{4 \\pi} p\\left(\\pm\\mu_i, \\phi ;-\\mu_{0}, \\phi_{0}\\right) \\exp\\left(-\\mu_{0}^{-1} \\tau^*\\right) \\\\\n",
    "\\tilde{\\mathcal{B}}(\\tau^*, \\pm\\mu_i, \\phi) &= \\left(\\pm \\frac{\\mu_i}{\\mu_0} + 1 \\right)^{-1} \\frac{\\omega^*_0 I_0}{(1 - f) 4 \\pi} p\\left(\\pm\\mu_i, \\phi ;-\\mu_{0}, \\phi_{0}\\right) \\exp\\left(-\\mu_{0}^{-1} \\tau^*\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f68b9a",
   "metadata": {},
   "source": [
    "The TMS correction substantially reduces the truncation error for all angles except those close to the direct beam. Thus, a second NT correction, named *IMS*, is required. For the IMS, we claim that $u_\\text{true} \\approx u_\\text{TMS} + u_\\text{IMS}$ where $u_\\text{IMS}$ is the true solution to\n",
    "\n",
    "$$\\mathcal{F}\\left(u_\\text{IMS}, \\tau, \\omega, p; -J_1 - J_2 - J_3\\right)$$\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{aligned}\n",
    "J_1 &= \\\\\n",
    "J_2 &= \\\\\n",
    "J_3 &=\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d680ae89",
   "metadata": {},
   "source": [
    "*TODO: Complete description of IMS. Also derive analytic solutions where possible*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada4fda8",
   "metadata": {},
   "source": [
    "### 3.7.2 Verification of full solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092253a9",
   "metadata": {},
   "source": [
    "[Skip verifications](#3.7.3-Computation-of-flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e868ead1",
   "metadata": {},
   "source": [
    "Test parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "320e873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntau = 2**9  # Number of tau grid points\n",
    "Nphi = 2**6 + 1  # Number of phi grid points\n",
    "\n",
    "tau_arr = np.linspace(0, tau0, Ntau)\n",
    "h = tau_arr[1] - tau_arr[0]  # grid spacing\n",
    "phi_arr, full_weights_phi = Clenshaw_Curtis_quad(Nphi)\n",
    "\n",
    "# Construct 1st derivative matrix with 2nd order accuracy\n",
    "first_deriv = np.zeros((Ntau, Ntau))\n",
    "diagonal = np.ones(Ntau) / (2 * h)\n",
    "first_deriv += np.diag(diagonal[:-1], 1)\n",
    "first_deriv += np.diag(-diagonal[:-1], -1)\n",
    "first_deriv[0, :3] = np.array([-3 / 2, 2, -1 / 2]) / h\n",
    "first_deriv[-1, -3:] = np.array([1 / 2, -2, 3 / 2]) / h\n",
    "first_deriv = first_deriv.T # This is due to tau being indexed by columns instead of rows\n",
    "\n",
    "mu_arr, u, flux_up, flux_down = PyDISORT(\n",
    "    b_pos, b_neg, False, NQuad, tau0, w0, Leg_coeffs, mu0, phi0, I0\n",
    ")\n",
    "full_weights_mu = np.concatenate((weights, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a90a8c",
   "metadata": {},
   "source": [
    "**Does the full solution satisfy the BCs?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa57b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(tau, phi):\n",
    "    # Delta-M scaling\n",
    "    tau = scale_tau * np.atleast_1d(tau)\n",
    "\n",
    "    # um must be real; the second term is already real\n",
    "    um = np.real(\n",
    "        np.einsum(\n",
    "            \"ijm, jmt -> imt\",\n",
    "            GC_collect,\n",
    "            np.exp(np.tensordot(eigenvals_collect, tau, axes=0)),\n",
    "            optimize=True,\n",
    "        )\n",
    "    ) + np.tensordot(B_collect, np.exp(-tau / mu0), axes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2698896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all tests\n"
     ]
    }
   ],
   "source": [
    "# At top of atmosphere\n",
    "assert np.allclose(\n",
    "    u(0, phi_arr)[N:, :],\n",
    "    np.tensordot(\n",
    "        np.repeat(np.atleast_1d(b_neg)[:, None], N // len(np.atleast_1d(b_neg))),\n",
    "        np.sum(np.cos(np.outer(phi0 - phi_arr, np.arange(NLeg))), axis=1),\n",
    "        axes=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# At bottom of atmosphere\n",
    "assert np.allclose(\n",
    "    u(tau0, phi_arr)[:N, :],\n",
    "    np.tensordot(\n",
    "        np.repeat(np.atleast_1d(b_pos)[:, None], N // len(np.atleast_1d(b_pos))),\n",
    "        np.sum(np.cos(np.outer(phi0 - phi_arr, np.arange(NLeg))), axis=1),\n",
    "        axes=0,\n",
    "    ),\n",
    ")\n",
    "print(\"Passed all tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70540fcc",
   "metadata": {},
   "source": [
    "**Does the full solution satisfy the radiative transfer equation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_cache = u(tau_arr, phi_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "787a2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LHS = mu_arr[:, None, None] * np.moveaxis(\n",
    "    np.tensordot(u_cache, first_deriv, axes=(1, 0)),\n",
    "    source=2,\n",
    "    destination=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae559251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'integrand = np.einsum(\\n    \"ijkl, ktl -> itjkl\",\\n    p_HG_muphi(mu_arr, phi_arr, mu_arr, phi_arr),\\n    u_cache,\\n    optimize=True,\\n)\\nRHS = (\\n    u_cache\\n    - (w0 / (4 * pi))\\n    * np.tensordot(\\n        np.tensordot(integrand, full_weights_mu, axes=(3, 0)),\\n        full_weights_phi,\\n        axes=(3, 0),\\n    )\\n    - (w0 * I0 / (4 * pi))\\n    * np.moveaxis(\\n        np.tensordot(\\n            p_HG_muphi(mu_arr, phi_arr, -mu0, phi0), np.exp(-tau_arr / mu0), axes=0\\n        ),\\n        source=2,\\n        destination=1,\\n    )\\n)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING: The integrand is a 5-dimensional tensor and so constructing it \n",
    "#          can be computationally intensive depending on parameters\n",
    "'''integrand = np.einsum(\n",
    "    \"ijkl, ktl -> itjkl\",\n",
    "    p_HG_muphi(mu_arr, phi_arr, mu_arr, phi_arr),\n",
    "    u_cache,\n",
    "    optimize=True,\n",
    ")\n",
    "RHS = (\n",
    "    u_cache\n",
    "    - (w0 / (4 * pi))\n",
    "    * np.tensordot(\n",
    "        np.tensordot(integrand, full_weights_mu, axes=(3, 0)),\n",
    "        full_weights_phi,\n",
    "        axes=(3, 0),\n",
    "    )\n",
    "    - (w0 * I0 / (4 * pi))\n",
    "    * np.moveaxis(\n",
    "        np.tensordot(\n",
    "            p_HG_muphi(mu_arr, phi_arr, -mu0, phi0), np.exp(-tau_arr / mu0), axes=0\n",
    "        ),\n",
    "        source=2,\n",
    "        destination=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"L2 error =\", np.linalg.norm(LHS - RHS))\n",
    "print(\"% error in L2 norm =\", np.linalg.norm(LHS - RHS)/np.linalg.norm(RHS))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82919f7",
   "metadata": {},
   "source": [
    "### 3.7.3 Computation of flux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe27fd8",
   "metadata": {},
   "source": [
    "`PyDISORT` also returns the positive and negative (hemispheric) flux functions. We have that\n",
    "\n",
    "$$\n",
    "F_\\text{total}^\\pm(\\tau) = F_\\text{diffuse}^\\pm(\\tau) + F_\\text{direct}^\\pm(\\tau)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21962c",
   "metadata": {},
   "source": [
    "Since the direct beam is\n",
    "\n",
    "$$u_\\text{direct}(\\tau, \\mu, \\phi) = I_0 \\delta(\\mu - \\mu_0) \\delta(\\phi - \\phi_0) \\exp\\left(-\\mu_{0}^{-1} \\tau\\right)$$\n",
    "\n",
    "and $\\mu_0 > 0$, we have \n",
    "\n",
    "$$F_\\text{direct}^+(\\tau) \\equiv 0, \\quad F_\\text{direct}^-(\\tau) = I_0 \\mu_0 \\exp\\left(-\\mu_{0}^{-1} \\tau\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f1c8c",
   "metadata": {},
   "source": [
    "The diffuse flux equals\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "F_\\text{diffuse}^\\pm(\\tau) &= \\int_{0}^{1} \\int_{0}^{2 \\pi} \\mu u\\left(\\tau, \\pm\\mu, \\phi\\right) \\mathrm{d} \\phi \\mathrm{d} \\mu \\\\\n",
    "& \\approx \\sum_{m=0} \\left(\\int_{0}^{1} \\mu u^m(\\tau, \\pm\\mu) \\mathrm{d} \\mu \\int_{0}^{2 \\pi} \\cos\\left(m\\left(\\phi_0 - \\phi\\right)\\right) \\mathrm{d} \\phi \\right) \\\\\n",
    "&= 2\\pi \\int_{0}^{1} \\mu u^0\\left(\\tau, \\pm\\mu\\right) \\mathrm{d} \\mu \\\\\n",
    "&\\approx 2\\pi \\sum_{i = 1} w_i\\mu_i u^0\\left(\\tau, \\pm\\mu_i\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where we used the cosine expansion of $u$ from section [3.2](#3.2-Re-derivation-of-equations-%286a%29-to-Re-derivation-of-equations-%286a%29-to-3.2-Re-derivation-of-equations-%286a%29-to-Re-derivation-of-equations-%286a%29-to-3.2-Re-derivation-of-equations-%286a%29-to-%286d%29-in-Stamnes-et.-al.,-1988). In the last line we approximated the $\\mu$ integral by Gauss-Legendre quadrature. Only the $0$th moment matters for the flux. With $\\delta-M$ scaling, we have\n",
    "\n",
    "$$\n",
    "F_\\text{direct}^-(\\tau) \\equiv (1 + \\omega_0 f) I_0 \\mu_0 \\exp\\left(-\\mu_{0}^{-1} \\tau\\right), \\quad F_\\text{diffuse}^\\pm(\\tau^*_0) \\approx 2\\pi \\sum_{i = 1} w_i\\mu_i u^{*0}\\left(\\tau^*_0, \\pm\\mu_i\\right)\n",
    "$$\n",
    "\n",
    "instead. Note that $\\tau$ has to be mapped to $\\tau^*$ before being inputted into $F_\\text{diffuse}^\\pm$. The upwelling and downwelling equal \n",
    "\n",
    "$$F_\\text{total}^+(0), \\quad F_\\text{total}^-(\\tau_0)$$ \n",
    "\n",
    "respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa1573",
   "metadata": {},
   "source": [
    "**IMPORTANT:** reminder that `PyDISORT` will output the **diffuse intensity** and the **total flux**. One will need to separately / manually add the intensity of the direct beam to get the total intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d8c134",
   "metadata": {},
   "source": [
    "#### 3.7.3.1 Verification of flux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba01a31",
   "metadata": {},
   "source": [
    "[Skip verification](#3.7.3.2-Computation-of-reflectivity-and-transmittivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad9364",
   "metadata": {},
   "source": [
    "**Does integrating the intensity functions produce the flux functions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2790cdd2",
   "metadata": {},
   "source": [
    "This will only be true if\n",
    "* `callable(p_for_NT_cor) == False`, because the corrections are applied only to the intensity and not the fluxes\n",
    "* We manually add the direct flux to `flux_up_test` and `flux_down_test`, since `PyDISORT` only outputs the diffuse, and not total, intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d345c6d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mu_arr_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3076\\1242819102.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m flux_up_test = np.tensordot(\n\u001b[0;32m      2\u001b[0m     np.tensordot(\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mmu_arr_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mu_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     ),\n\u001b[0;32m      5\u001b[0m     \u001b[0mfull_weights_phi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mu_arr_pos' is not defined"
     ]
    }
   ],
   "source": [
    "flux_up_test = np.tensordot(\n",
    "    np.tensordot(\n",
    "        mu_arr_pos[:, None, None] * u_cache[:N, :], weights, axes=(0, 0)\n",
    "    ),\n",
    "    full_weights_phi,\n",
    "    axes=(1, 0),\n",
    ")\n",
    "flux_down_test = np.tensordot(\n",
    "    np.tensordot(\n",
    "        mu_arr_pos[:, None, None] * u_cache[N:, :], weights, axes=(0, 0)\n",
    "    ),\n",
    "    full_weights_phi,\n",
    "    axes=(1, 0),\n",
    ")\n",
    "# Add the direct flux and account for delta-M scaling\n",
    "if np.issubdtype(type(f), np.number):\n",
    "    flux_down_test += I0 * mu0 * np.exp(-tau_arr / mu0) \n",
    "else:\n",
    "    flux_down_test += (1 + w0 * f) * I0 * mu0 * np.exp(-tau_arr / mu0)\n",
    "    \n",
    "\n",
    "assert np.allclose(flux_up_test, flux_up(tau_arr))\n",
    "assert np.allclose(flux_down_test, flux_down(tau_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ccfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Upwelling =\", flux_up(0))\n",
    "print(\"Downwelling =\", flux_down(tau0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62131840",
   "metadata": {},
   "source": [
    "#### 3.7.3.2 Computation of reflectivity and transmittivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d10ef",
   "metadata": {},
   "source": [
    "In order to compute the reflectivity and transmittivity, we first need to determine the incident flux. The incident flux from the direct beam is $I_0 \\mu_0 \\exp\\left(-\\mu_{0}^{-1} \\tau\\right)$ or $(1 + \\omega_0 f) I_0 \\mu_0 \\exp\\left(-\\mu_{0}^{-1} \\tau\\right)$ if $\\delta-M$ scaling is enabled. Recall that the boundary conditions are\n",
    "\n",
    "$$\n",
    "u\\left(\\tau_0, \\mu_i, \\phi \\right) = \\sum_{m = 0}^{\\text{NLeg}}b^+_{im}\\cos(m(\\phi_0 - \\phi)), \\quad u(0, -\\mu_i, \\phi) = \\sum_{m = 0}^{\\text{NLeg}}b^-_{im}\\cos(m(\\phi_0 - \\phi)) \\quad i = 1, \\dots, N\n",
    "$$\n",
    "\n",
    "The incident flux from the BCs, which we denote $F_{b^\\pm}$, are\n",
    "\n",
    "$$F_{b^\\pm} = 2 \\pi \\sum_{i = 0}^N w_i \\mu_i b^\\pm_{i0}$$\n",
    "\n",
    "respectively, where $w_i$ are the Gauss-Legendre weights.  Once again, only the $0$th moment matters for the flux. If the BCs are constant over $\\mu$, we will have \n",
    "\n",
    "$$F_{b^\\pm} = \\pi b^\\pm$$\n",
    "\n",
    "instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720a5dd7",
   "metadata": {},
   "source": [
    "Reflectivity, $R$, and transmittivity, $T$, calculations only make sense if the incident radiation comes entirely from one side of the atmosphere, usually downwards onto the top layer. In addition, we generally want to calculate reflectivity and transmittivity with respect to a specific source. As an example, we calculate the reflectivity and transmittivity with respect to the direct beam:\n",
    "\n",
    "$$R = \\frac{F_\\text{Total}^+(0)}{I_0 \\mu_0}, \\quad T = \\frac{F_\\text{Total}^-(\\tau_0)}{I_0 \\mu_0}$$\n",
    "\n",
    "which requires the BCs, $b^\\pm = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794cad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_up, flux_down = PyDISORT(0, 0, True, NQuad, tau0, w0, Leg_coeffs, mu0, phi0, I0)[1:3]\n",
    "\n",
    "\n",
    "print(\"Reflectivity, R =\", flux_up(0) / (I0 * mu0))\n",
    "print(\"Transmittivity, T =\", flux_down(tau0) / (I0 * mu0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd1639",
   "metadata": {},
   "source": [
    "### 3.7.4 Timing PyDISORT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7894cda",
   "metadata": {},
   "source": [
    "[Skip section](#4.-Solving-for-multiple-atmospheric-layers-%28TODO%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ab1a9",
   "metadata": {},
   "source": [
    "The time taken will of course be parameter-dependent, but this should give a sense of the speed of `PyDISORT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146bc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters which most affect the speed\n",
    "print(\"NLeg, NQuad, Ntau, Nphi =\", NLeg, NQuad, Ntau, Nphi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416dc04a",
   "metadata": {},
   "source": [
    "**Time taken to solve the radiative transfer equation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For intensity\n",
    "%timeit PyDISORT(b_pos, b_neg, False, NQuad, tau0, w0, Leg_coeffs, mu0, phi0, I0)\n",
    "\n",
    "# For flux\n",
    "%timeit PyDISORT(b_pos, b_neg, True, NQuad, tau0, w0, Leg_coeffs, mu0, phi0, I0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41446198",
   "metadata": {},
   "source": [
    "**Time taken to evaluate the solution at a point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For intensity\n",
    "%timeit u(tau_arr[Ntau//2], phi_arr[Nphi//2])\n",
    "\n",
    "# For flux\n",
    "%timeit flux_up(0)\n",
    "%timeit flux_down(tau0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ce759",
   "metadata": {},
   "source": [
    "# 4. Solving for multiple atmospheric layers (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e18b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aed4cb45",
   "metadata": {},
   "source": [
    "<!--bibtex\n",
    "\n",
    "@article{NT1988,\n",
    "title = {Algorithms for radiative intensity calculations in moderately thick atmospheres using a truncation approximation},\n",
    "journal = {Journal of Quantitative Spectroscopy and Radiative Transfer},\n",
    "volume = {40},\n",
    "number = {1},\n",
    "pages = {51-69},\n",
    "year = {1988},\n",
    "issn = {0022-4073},\n",
    "doi = {https://doi.org/10.1016/0022-4073(88)90031-3},\n",
    "url = {https://www.sciencedirect.com/science/article/pii/0022407388900313},\n",
    "author = {T. Nakajima and M. Tanaka},\n",
    "abstract = {The efficiency of numerical calculations is discussed for selected algorithms employing the discrete ordinate method and the truncation approximation for the solar radiative intensity in moderately thick, plane-parallel scattering atmospheres. It is found that truncation of the phase function causes a significant error in the computed intensity and the magnitude of this error depends significantly on how the intensity is retrieved from the truncated radiative transfer equation. A newly developed retrieval algorithm, the IMS- method, yields the intensity field with an error ⪅1% when the number of discrete path is as small as 10 in the hemisphere for aerosol-laden atmospheres with optical thickness ⪅1.}\n",
    "}\n",
    "\n",
    "@article{YTA1971,\n",
    "title = {Radiative heat transfer in water clouds by infrared radiation},\n",
    "journal = {Journal of Quantitative Spectroscopy and Radiative Transfer},\n",
    "volume = {11},\n",
    "number = {6},\n",
    "pages = {697-708},\n",
    "year = {1971},\n",
    "issn = {0022-4073},\n",
    "doi = {https://doi.org/10.1016/0022-4073(71)90048-3},\n",
    "url = {https://www.sciencedirect.com/science/article/pii/0022407371900483},\n",
    "author = {Giichi Yamamoto and Masayuki Tanaka and Shoji Asano},\n",
    "abstract = {Radiative heat transfer in water clouds is studied by the method of discrete ordinates, taking into account not only scattering, absorption and emission by cloud droplets but also absorption and emission by water vapor in the cloud. According to Semuelson the method of discrete ordinates is not very amenable to studies involving the intermediate optical thickness, because of instabilities that are inherent in the method for the intermediate optical thickness. A method of avoiding these instabilities is shown in this paper. Numerical calculation for the spectral region from 5 to 40 μ was carried out on the model altostratus clouds, and that only for the window region on the model stratocumulus and nimbostratus clouds. The radiative temperature change in a very thin cloud is everywhere cooling. With increasing cloud thickness, however, the upper parts of the cloud undergo cooling, while the lower parts undergo heating. The rate of both heating and cooling is largest near the surface. In a semi-infinitely thick cloud the cloud top undergoes cooling at a rate of about 30°C/hr and effective cooling extends to about 100 m interior from the cloud boundary.}\n",
    "}\n",
    "\n",
    "@book{Cha1960, \n",
    "      author = \"S.  Chandrasekhar\",\n",
    "      title = \"Radiative Transfer\",\n",
    "      year = \"1960\",\n",
    "      publisher = \"Dover\",\n",
    "}\n",
    "\n",
    "@article{Wis1977,\n",
    "      author = \"W. J.  Wiscombe\",\n",
    "      title = \"The Delta–M Method: Rapid Yet Accurate Radiative Flux Calculations for Strongly Asymmetric Phase Functions\",\n",
    "      journal = \"Journal of Atmospheric Sciences\",\n",
    "      year = \"1977\",\n",
    "      publisher = \"American Meteorological Society\",\n",
    "      address = \"Boston MA, USA\",\n",
    "      volume = \"34\",\n",
    "      number = \"9\",\n",
    "      doi = \"10.1175/1520-0469(1977)034<1408:TDMRYA>2.0.CO;2\",\n",
    "      pages=      \"1408 - 1422\",\n",
    "      url = \"https://journals.ametsoc.org/view/journals/atsc/34/9/1520-0469_1977_034_1408_tdmrya_2_0_co_2.xml\"\n",
    "}\n",
    "\n",
    "@article{Syk1951,\n",
    "    author = {Sykes, J. B.},\n",
    "    title = \"{Approximate Integration of the Equation of Transfer}\",\n",
    "    journal = {Monthly Notices of the Royal Astronomical Society},\n",
    "    volume = {111},\n",
    "    number = {4},\n",
    "    pages = {377-386},\n",
    "    year = {1951},\n",
    "    month = {08},\n",
    "    abstract = \"{The value of numerical integration in obtaining approximate solutions of an equation of transfer, and the different methods at our disposal, are discussed. It is shown that although the Newton-Cotes method, used by Kourganoff, is better than the Gauss method, used by Chandrasekhar, both are inferior to a new method, the double-Gauss, discovered by the author. The errors in the approximate values of the source-function and the limb-darkening in all three methods are tabulated for various approximations, and illustrated by graphs.}\",\n",
    "    issn = {0035-8711},\n",
    "    doi = {10.1093/mnras/111.4.377},\n",
    "    url = {https://doi.org/10.1093/mnras/111.4.377},\n",
    "    eprint = {https://academic.oup.com/mnras/article-pdf/111/4/377/8077435/mnras111-0377.pdf},\n",
    "}\n",
    "\n",
    "\n",
    "@article{STWJ1988,\n",
    "author = {Knut Stamnes and S-Chee Tsay and Warren Wiscombe and Kolf Jayaweera},\n",
    "journal = {Appl. Opt.},\n",
    "keywords = {Electromagnetic radiation; Multiple scattering; Optical depth; Radiative transfer; Reflection; Thermal emission},\n",
    "number = {12},\n",
    "pages = {2502--2509},\n",
    "publisher = {Optica Publishing Group},\n",
    "title = {Numerically stable algorithm for discrete-ordinate-method radiative transfer in multiple scattering and emitting layered media},\n",
    "volume = {27},\n",
    "month = {Jun},\n",
    "year = {1988},\n",
    "url = {http://opg.optica.org/ao/abstract.cfm?URI=ao-27-12-2502},\n",
    "doi = {10.1364/AO.27.002502},\n",
    "abstract = {We summarize an advanced, thoroughly documented, and quite general purpose discrete ordinate algorithm for time-independent transfer calculations in vertically inhomogeneous, nonisothermal, plane-parallel media. Atmospheric applications ranging from the UV to the radar region of the electromagnetic spectrum are possible. The physical processes included are thermal emission, scattering, absorption, and bidirectional reflection and emissionat the lower boundary. The medium may be forced at the top boundary by parallel or diffuse radiation and by internal and boundary thermal sources as well. We provide a brief account of the theoretical basis as well as a discussion of the numerical implementation of the theory. The recent advances made by ourselves and our collaborators---advances in both formulation and numerical solution---are all incorporated in the algorithm. Prominent among these advances are the complete conquest of two ill-conditioning problems which afflicted all previous discrete ordinate implementations: (1) the computation of eigenvalues and eigenvectors and (2) the inversion of the matrix determining the constants of integration. Copies of the fortran program on microcomputer diskettes are available for interested users.},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "@article{STL2000,\n",
    "author = {Stamnes, Knut and Tsay, Si-Chee and Wiscombe, Warren and Laszlo, Istvan and Einaudi, Franco},\n",
    "year = {2000},\n",
    "month = {02},\n",
    "pages = {},\n",
    "title = {General Purpose Fortran Program for Discrete-Ordinate-Method Radiative Transfer in Scattering and Emitting Layered Media: An Update of DISORT}\n",
    "}\n",
    "\n",
    "@article{SS1981,\n",
    "      author = \"Knut  Stamnes and Roy A.  Swanson\",\n",
    "      title = \"A New Look at the Discrete Ordinate Method for Radiative Transfer Calculations in Anisotropically Scattering Atmospheres\",\n",
    "      journal = \"Journal of Atmospheric Sciences\",\n",
    "      year = \"1981\",\n",
    "      publisher = \"American Meteorological Society\",\n",
    "      address = \"Boston MA, USA\",\n",
    "      volume = \"38\",\n",
    "      number = \"2\",\n",
    "      doi = \"10.1175/1520-0469(1981)038<0387:ANLATD>2.0.CO;2\",\n",
    "      pages=      \"387 - 399\",\n",
    "      url = \"https://journals.ametsoc.org/view/journals/atsc/38/2/1520-0469_1981_038_0387_anlatd_2_0_co_2.xml\"\n",
    "}\n",
    "\n",
    "@article{SC1984,\n",
    "title = {A new multi-layer discrete ordinate approach to radiative transfer in vertically inhomogeneous atmospheres},\n",
    "journal = {Journal of Quantitative Spectroscopy and Radiative Transfer},\n",
    "volume = {31},\n",
    "number = {3},\n",
    "pages = {273-282},\n",
    "year = {1984},\n",
    "issn = {0022-4073},\n",
    "doi = {https://doi.org/10.1016/0022-4073(84)90031-1},\n",
    "url = {https://www.sciencedirect.com/science/article/pii/0022407384900311},\n",
    "author = {Knut Stamnes and Paul Conklin},\n",
    "abstract = {A recently developed matrix formulation of the discrete ordinate method is extended for application to an inhomogeneous atmosphere. The solution yields fluxes, as well as the complete azimuthal dependence of the intensity at any level in the atmosphere. The numerical aspects of the solution are discussed and numerical verification is provided by comparing computed results with those obtained by other methods. In particular, it is shown that a simple scaling scheme, which removes the positive exponentials in the coefficient matrix when solving for the constants of integration, provides unconditionally stable solutions for arbitrary optical thicknesses. An assessment of the accuracy to be expected is also provided, and it is shown that low-order discrete ordinate approximations yield very accurate flux values.}\n",
    "}\n",
    "\n",
    "@article{MH2017,\n",
    "title = {A demonstration of adjoint methods for multi-dimensional remote sensing of the atmosphere and surface},\n",
    "journal = {Journal of Quantitative Spectroscopy and Radiative Transfer},\n",
    "volume = {204},\n",
    "pages = {215-231},\n",
    "year = {2018},\n",
    "issn = {0022-4073},\n",
    "doi = {https://doi.org/10.1016/j.jqsrt.2017.09.031},\n",
    "url = {https://www.sciencedirect.com/science/article/pii/S0022407317305198},\n",
    "author = {William G.K. Martin and Otto P. Hasekamp},\n",
    "keywords = {Adjoint methods, Three-dimensional vector radiative transfer, Linearization, Remote sensing, Parameter derivatives, Searchlight functions},\n",
    "abstract = {In previous work, we derived the adjoint method as a computationally efficient path to three-dimensional (3D) retrievals of clouds and aerosols. In this paper we will demonstrate the use of adjoint methods for retrieving two-dimensional (2D) fields of cloud extinction. The demonstration uses a new 2D radiative transfer solver (FSDOM). This radiation code was augmented with adjoint methods to allow efficient derivative calculations needed to retrieve cloud and surface properties from multi-angle reflectance measurements. The code was then used in three synthetic retrieval studies. Our retrieval algorithm adjusts the cloud extinction field and surface albedo to minimize the measurement misfit function with a gradient-based, quasi-Newton approach. At each step we compute the value of the misfit function and its gradient with two calls to the solver FSDOM. First we solve the forward radiative transfer equation to compute the residual misfit with measurements, and second we solve the adjoint radiative transfer equation to compute the gradient of the misfit function with respect to all unknowns. The synthetic retrieval studies verify that adjoint methods are scalable to retrieval problems with many measurements and unknowns. We can retrieve the vertically-integrated optical depth of moderately thick clouds as a function of the horizontal coordinate. It is also possible to retrieve the vertical profile of clouds that are separated by clear regions. The vertical profile retrievals improve for smaller cloud fractions. This leads to the conclusion that cloud edges actually increase the amount of information that is available for retrieving the vertical profile of clouds. However, to exploit this information one must retrieve the horizontally heterogeneous cloud properties with a 2D (or 3D) model. This prototype shows that adjoint methods can efficiently compute the gradient of the misfit function. This work paves the way for the application of similar methods to 3D remote sensing problems.}\n",
    "}\n",
    "\n",
    "@article{MCB2014,\n",
    "title = {Adjoint methods for adjusting three-dimensional atmosphere and surface properties to fit multi-angle/multi-pixel polarimetric measurements},\n",
    "journal = {Journal of Quantitative Spectroscopy and Radiative Transfer},\n",
    "volume = {144},\n",
    "pages = {68-85},\n",
    "year = {2014},\n",
    "issn = {0022-4073},\n",
    "doi = {https://doi.org/10.1016/j.jqsrt.2014.03.030},\n",
    "url = {https://www.sciencedirect.com/science/article/pii/S002240731400154X},\n",
    "author = {William Martin and Brian Cairns and Guillaume Bal},\n",
    "keywords = {Adjoint methods, Three-dimensional vector radiative transfer, Linearization, Remote sensing, Parameter derivatives},\n",
    "abstract = {This paper derives an efficient procedure for using the three-dimensional (3D) vector radiative transfer equation (VRTE) to adjust atmosphere and surface properties and improve their fit with multi-angle/multi-pixel radiometric and polarimetric measurements of scattered sunlight. The proposed adjoint method uses the 3D VRTE to compute the measurement misfit function and the adjoint 3D VRTE to compute its gradient with respect to all unknown parameters. In the remote sensing problems of interest, the scalar-valued misfit function quantifies agreement with data as a function of atmosphere and surface properties, and its gradient guides the search through this parameter space. Remote sensing of the atmosphere and surface in a three-dimensional region may require thousands of unknown parameters and millions of data points. Many approaches would require calls to the 3D VRTE solver in proportion to the number of unknown parameters or measurements. To avoid this issue of scale, we focus on computing the gradient of the misfit function as an alternative to the Jacobian of the measurement operator. The resulting adjoint method provides a way to adjust 3D atmosphere and surface properties with only two calls to the 3D VRTE solver for each spectral channel, regardless of the number of retrieval parameters, measurement view angles or pixels. This gives a procedure for adjusting atmosphere and surface parameters that will scale to the large problems of 3D remote sensing. For certain types of multi-angle/multi-pixel polarimetric measurements, this encourages the development of a new class of three-dimensional retrieval algorithms with more flexible parametrizations of spatial heterogeneity, less reliance on data screening procedures, and improved coverage in terms of the resolved physical processes in the Earth׳s atmosphere.}\n",
    "}\n",
    "\n",
    "@article{LSJLTWS2015,\n",
    "title = {Improved discrete ordinate solutions in the presence of an anisotropically reflecting lower boundary: Upgrades of the DISORT computational tool},\n",
    "journal = {Journal of Quantitative Spectroscopy and Radiative Transfer},\n",
    "volume = {157},\n",
    "pages = {119-134},\n",
    "year = {2015},\n",
    "issn = {0022-4073},\n",
    "doi = {https://doi.org/10.1016/j.jqsrt.2015.02.014},\n",
    "url = {https://www.sciencedirect.com/science/article/pii/S0022407315000679},\n",
    "author = {Z. Lin and S. Stamnes and Z. Jin and I. Laszlo and S.-C. Tsay and W.J. Wiscombe and K. Stamnes},\n",
    "keywords = {Radiative transfer model, BRDF, Cox–Munk, Ross–Li, RPV, Single scattering correction},\n",
    "abstract = {A successor version 3 of DISORT (DISORT3) is presented with important upgrades that improve the accuracy, efficiency, and stability of the algorithm. Compared with version 2 (DISORT2 released in 2000) these upgrades include (a) a redesigned BRDF computation that improves both speed and accuracy, (b) a revised treatment of the single scattering correction, and (c) additional efficiency and stability upgrades for beam sources. In DISORT3 the BRDF computation is improved in the following three ways: (i) the Fourier decomposition is prepared “off-line”, thus avoiding the repeated internal computations done in DISORT2; (ii) a large enough number of terms in the Fourier expansion of the BRDF is employed to guarantee accurate values of the expansion coefficients (default is 200 instead of 50 in DISORT2); (iii) in the post-processing step the reflection of the direct attenuated beam from the lower boundary is included resulting in a more accurate single scattering correction. These improvements in the treatment of the BRDF have led to improved accuracy and a several-fold increase in speed. In addition, the stability of beam sources has been improved by removing a singularity occurring when the cosine of the incident beam angle is too close to the reciprocal of any of the eigenvalues. The efficiency for beam sources has been further improved from reducing by a factor of 2 (compared to DISORT2) the dimension of the linear system of equations that must be solved to obtain the particular solutions, and by replacing the LINPAK routines used in DISORT2 by LAPACK 3.5 in DISORT3. These beam source stability and efficiency upgrades bring enhanced stability and an additional 5–7% improvement in speed. Numerical results are provided to demonstrate and quantify the improvements in accuracy and efficiency of DISORT3 compared to DISORT2.}\n",
    "}\n",
    "\n",
    "@article {JWW1976,\n",
    "      author = \"J. H.  Joseph and W. J.  Wiscombe and J. A.  Weinman\",\n",
    "      title = \"The Delta-Eddington Approximation for Radiative Flux Transfer\",\n",
    "      journal = \"Journal of Atmospheric Sciences\",\n",
    "      year = \"1976\",\n",
    "      publisher = \"American Meteorological Society\",\n",
    "      address = \"Boston MA, USA\",\n",
    "      volume = \"33\",\n",
    "      number = \"12\",\n",
    "      doi = \"10.1175/1520-0469(1976)033<2452:TDEAFR>2.0.CO;2\",\n",
    "      pages=      \"2452 - 2459\",\n",
    "      url = \"https://journals.ametsoc.org/view/journals/atsc/33/12/1520-0469_1976_033_2452_tdeafr_2_0_co_2.xml\"\n",
    "}\n",
    "\n",
    "@Article{HMMNPW2017,\n",
    "AUTHOR = {Hase, N. and Miller, S. M. and Maa{\\ss}, P. and Notholt, J. and Palm, M. and Warneke, T.},\n",
    "TITLE = {Atmospheric inverse modeling via sparse reconstruction},\n",
    "JOURNAL = {Geoscientific Model Development},\n",
    "VOLUME = {10},\n",
    "YEAR = {2017},\n",
    "NUMBER = {10},\n",
    "PAGES = {3695--3713},\n",
    "URL = {https://gmd.copernicus.org/articles/10/3695/2017/},\n",
    "DOI = {10.5194/gmd-10-3695-2017}\n",
    "}\n",
    "\n",
    "@article {FL1992,\n",
    "      author = \"Qiang  Fu and K. N.  Liou\",\n",
    "      title = \"On the Correlated k-Distribution Method for Radiative Transfer in Nonhomogeneous Atmospheres\",\n",
    "      journal = \"Journal of Atmospheric Sciences\",\n",
    "      year = \"1992\",\n",
    "      publisher = \"American Meteorological Society\",\n",
    "      address = \"Boston MA, USA\",\n",
    "      volume = \"49\",\n",
    "      number = \"22\",\n",
    "      doi = \"10.1175/1520-0469(1992)049<2139:OTCDMF>2.0.CO;2\",\n",
    "      pages=      \"2139 - 2156\",\n",
    "      url = \"https://journals.ametsoc.org/view/journals/atsc/49/22/1520-0469_1992_049_2139_otcdmf_2_0_co_2.xml\"\n",
    "}\n",
    "\n",
    "@inproceedings{FJ1999,\n",
    "  title={Computer-based underwater imaging analysis},\n",
    "  author={Georges R. Fournier and Miroslaw Jonasz},\n",
    "  booktitle={Optics \\& Photonics},\n",
    "  year={1999}\n",
    "}\n",
    "\n",
    "@article{DM2010,\n",
    "\tdoi = {10.1088/0034-4885/73/2/026801},\n",
    "\turl = {https://doi.org/10.1088/0034-4885/73/2/026801},\n",
    "\tyear = 2010,\n",
    "\tmonth = {jan},\n",
    "\tpublisher = {{IOP} Publishing},\n",
    "\tvolume = {73},\n",
    "\tnumber = {2},\n",
    "\tpages = {026801},\n",
    "\tauthor = {Anthony B Davis and Alexander Marshak},\n",
    "\ttitle = {Solar radiation transport in the cloudy atmosphere: a 3D perspective on observations and climate impacts},\n",
    "\tjournal = {Reports on Progress in Physics},\n",
    "\tabstract = {The interplay of sunlight with clouds is a ubiquitous and often pleasant visual experience, but it conjures up major challenges for weather, climate, environmental science and beyond. Those engaged in the characterization of clouds (and the clear air nearby) by remote sensing methods are even more confronted. The problem comes, on the one hand, from the spatial complexity of real clouds and, on the other hand, from the dominance of multiple scattering in the radiation transport. The former ingredient contrasts sharply with the still popular representation of clouds as homogeneous plane-parallel slabs for the purposes of radiative transfer computations. In typical cloud scenes the opposite asymptotic transport regimes of diffusion and ballistic propagation coexist. We survey the three-dimensional (3D) atmospheric radiative transfer literature over the past 50 years and identify three concurrent and intertwining thrusts: first, how to assess the damage (bias) caused by 3D effects in the operational 1D radiative transfer models? Second, how to mitigate this damage? Finally, can we exploit 3D radiative transfer phenomena to innovate observation methods and technologies? We quickly realize that the smallest scale resolved computationally or observationally may be artificial but is nonetheless a key quantity that separates the 3D radiative transfer solutions into two broad and complementary classes: stochastic and deterministic. Both approaches draw on classic and contemporary statistical, mathematical and computational physics.}\n",
    "}\n",
    "\n",
    "@article{DFDM2021,\n",
    "      author = \"Linda Forster and Anthony B. Davis and David J. Diner and Bernhard Mayer\",\n",
    "      title = \"Toward Cloud Tomography from Space Using MISR and MODIS: Locating the “Veiled Core” in Opaque Convective Clouds\",\n",
    "      journal = \"Journal of the Atmospheric Sciences\",\n",
    "      year = \"2021\",\n",
    "      publisher = \"American Meteorological Society\",\n",
    "      address = \"Boston MA, USA\",\n",
    "      volume = \"78\",\n",
    "      number = \"1\",\n",
    "      doi = \"10.1175/JAS-D-19-0262.1\",\n",
    "      pages=      \"155 - 166\",\n",
    "      url = \"https://journals.ametsoc.org/view/journals/atsc/78/1/jas-d-19-0262.1.xml\"\n",
    "}\n",
    "\n",
    "@article{DDET2022,\n",
    "title = {Cloud tomographic retrieval algorithms. I: Surrogate minimization method},\n",
    "journal = {Journal of Quantitative Spectroscopy and Radiative Transfer},\n",
    "volume = {277},\n",
    "pages = {107954},\n",
    "year = {2022},\n",
    "issn = {0022-4073},\n",
    "doi = {https://doi.org/10.1016/j.jqsrt.2021.107954},\n",
    "url = {https://www.sciencedirect.com/science/article/pii/S0022407321004465},\n",
    "author = {Adrian Doicu and Alexandru Doicu and Dmitry Efremenko and Thomas Trautmann},\n",
    "keywords = {Cloud tomographic retrieval, Multi-dimensional models},\n",
    "abstract = {A cloud tomographic retrieval algorithm relying on (i) the spherical harmonics discrete ordinate method for computing the radiative transfer and (ii) the surrogate minimization method for solving the inverse problem has been designed. The retrieval algorithm uses regularization, accelerated projected gradient methods, and two types of surrogate functions. The performances of the retrieval algorithm are analyzed on a few synthetic two- and three-dimensional problems.}\n",
    "}\n",
    "\n",
    "@misc{Sta1999, \n",
    "\ttitle={LLLab disort website}, \n",
    "\turl={http://www.rtatmocn.com/disort/}, \n",
    "\tjournal={Light and Life Lab (LLLab)}, \n",
    "\tauthor={Stamnes, S.}, \n",
    "\tyear={1999}\n",
    "} \n",
    "\n",
    "@INPROCEEDINGS{ALHSAV2020,\n",
    "  author={Aides, Amit and Levis, Aviad and Holodovsky, Vadim and Schechner, Yoav Y. and Althausen, Dietrich and Vainiger, Adi},\n",
    "  booktitle={2020 IEEE International Conference on Computational Photography (ICCP)}, \n",
    "  title={Distributed Sky Imaging Radiometry and Tomography}, \n",
    "  year={2020},\n",
    "  volume={},\n",
    "  number={},\n",
    "  pages={1-12},\n",
    "  doi={10.1109/ICCP48838.2020.9105241}}\n",
    "\n",
    "@article {MW1980,\n",
    "      author = \"W. E.  Meador and W. R.  Weaver\",\n",
    "      title = \"Two-Stream Approximations to Radiative Transfer in Planetary Atmospheres: A Unified Description of Existing Methods and a New Improvement\",\n",
    "      journal = \"Journal of Atmospheric Sciences\",\n",
    "      year = \"1980\",\n",
    "      publisher = \"American Meteorological Society\",\n",
    "      address = \"Boston MA, USA\",\n",
    "      volume = \"37\",\n",
    "      number = \"3\",\n",
    "      doi = \"10.1175/1520-0469(1980)037<0630:TSATRT>2.0.CO;2\",\n",
    "      pages=      \"630 - 643\",\n",
    "      url = \"https://journals.ametsoc.org/view/journals/atsc/37/3/1520-0469_1980_037_0630_tsatrt_2_0_co_2.xml\"\n",
    "}\n",
    "\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2da50",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<a id=\"cite-STWJ1988\"/><sup><a href=#ref-1>[^]</a><a href=#ref-4>[^]</a><a href=#ref-6>[^]</a><a href=#ref-8>[^]</a><a href=#ref-14>[^]</a><a href=#ref-15>[^]</a><a href=#ref-17>[^]</a><a href=#ref-19>[^]</a></sup>Knut Stamnes and S-Chee Tsay and Warren Wiscombe and Kolf Jayaweera. 1988. _Numerically stable algorithm for discrete-ordinate-method radiative transfer in multiple scattering and emitting layered media_. [URL](http://opg.optica.org/ao/abstract.cfm?URI=ao-27-12-2502)\n",
    "\n",
    "<a id=\"cite-Sta1999\"/><sup><a href=#ref-2>[^]</a><a href=#ref-5>[^]</a><a href=#ref-7>[^]</a></sup>Stamnes, S.. 1999. _LLLab disort website_. [URL](http://www.rtatmocn.com/disort/)\n",
    "\n",
    "<a id=\"cite-SC1984\"/><sup><a href=#ref-3>[^]</a><a href=#ref-12>[^]</a></sup>Knut Stamnes and Paul Conklin. 1984. _A new multi-layer discrete ordinate approach to radiative transfer in vertically inhomogeneous atmospheres_. [URL](https://www.sciencedirect.com/science/article/pii/0022407384900311)\n",
    "\n",
    "<a id=\"cite-MW1980\"/><sup><a href=#ref-9>[^]</a><a href=#ref-13>[^]</a></sup>W. E.  Meador and W. R.  Weaver. 1980. _Two-Stream Approximations to Radiative Transfer in Planetary Atmospheres: A Unified Description of Existing Methods and a New Improvement_. [URL](https://journals.ametsoc.org/view/journals/atsc/37/3/1520-0469_1980_037_0630_tsatrt_2_0_co_2.xml)\n",
    "\n",
    "<a id=\"cite-Wis1977\"/><sup><a href=#ref-10>[^]</a><a href=#ref-16>[^]</a></sup>W. J.  Wiscombe. 1977. _The Delta–M Method: Rapid Yet Accurate Radiative Flux Calculations for Strongly Asymmetric Phase Functions_. [URL](https://journals.ametsoc.org/view/journals/atsc/34/9/1520-0469_1977_034_1408_tdmrya_2_0_co_2.xml)\n",
    "\n",
    "<a id=\"cite-JWW1976\"/><sup><a href=#ref-11>[^]</a></sup>J. H.  Joseph and W. J.  Wiscombe and J. A.  Weinman. 1976. _The Delta-Eddington Approximation for Radiative Flux Transfer_. [URL](https://journals.ametsoc.org/view/journals/atsc/33/12/1520-0469_1976_033_2452_tdeafr_2_0_co_2.xml)\n",
    "\n",
    "<a id=\"cite-Syk1951\"/><sup><a href=#ref-18>[^]</a></sup>Sykes, J. B.. 1951. _Approximate Integration of the Equation of Transfer_. [URL](https://doi.org/10.1093/mnras/111.4.377)\n",
    "\n",
    "<a id=\"cite-NT1988\"/><sup><a href=#ref-20>[^]</a></sup>T. Nakajima and M. Tanaka. 1988. _Algorithms for radiative intensity calculations in moderately thick atmospheres using a truncation approximation_. [URL](https://www.sciencedirect.com/science/article/pii/0022407388900313)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
